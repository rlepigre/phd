\Include{Macros}

\Caml(
  open ProofTree
  open Diagrams
  open Lang
  open OCamlVerbatim

  let sp = <$\mcolor(white){:}|\mcolor(white){:}$>

  let vs a = <$ ⟦\f(a)⟧ $>
  let ss a = <$ ⟦\f(a)⟧^⊥ $>
  let ts a = <$ ⟦\f(a)⟧^{⊥⊥} $>

  let mt = mathsText
  let wbox = <$\mathsize{3.}{\wbox}$>
  let bbox = <$\mathsize{3.}{\bbox}$>

  let mif = mathsText ([tT "if"])
)

\Configure_math_macro{\v}{ syntax = string; }
\Configure_math_macro{\t}{ syntax = string; }
\Configure_math_macro{\s}{ syntax = string; }
\Configure_math_macro{\p}{ syntax = string; }
\Configure_math_macro{\f}{ syntax = string; }
\Configure_math_macro{\o}{ syntax = string; }
\Configure_math_macro{\subs}{ syntax = string; }
\Configure_math_macro{\vs}{ syntax = string; }
\Configure_math_macro{\ss}{ syntax = string; }
\Configure_math_macro{\ts}{ syntax = string; }

\Caml(
let r_arrow_i =
  <$\binaryRN{⇒_i}{Ξ ⊢ \t{λx t} ∈ \f{A ⇒ B} ⊂ C}
    {Ξ, \v{εx∈A(t∉B)} ≠ \v{□} ⊢ \t{t[x ≔ εx∈A(t∉B)]} : \f{B}}
    {Ξ ⊢ \t{λx t} : C}$>

let r_arrow_e =
  <$\binaryRN{⇒_e}{Ξ ⊢ \t{t} : \f{A ⇒ B}}
    {Ξ ⊢ \t{u} : \f{A}}{Ξ ⊢ \t{t u} : \f{B}}$>

let r_ax =
  <$\binaryRN{Ax}{Ξ ⊢ \v{εx∈A(t∉B)} ∈ A ⊂ C}
    {Ξ ⊢ \v{εx∈A(t∉B)} ≠ \v{□}}
    {Ξ ⊢ \v{εx∈A(t∉B)} : C}$>

let r_arrow_ee =
  <$\ternaryRN{⇒_{e,{∈}}}{Ξ ⊢ \t{t} : \f{u∈A ⇒ B}}
    {Ξ ⊢ \t{u} : \f{A}}{Ξ ⊢ v ≡ u}{Ξ ⊢ \t{t u} : \f{B}}$>

let r_mu =
  <$\unaryRN{μ}{Ξ ⊢ \t{t[α ≔ εα∈A(t∉A)]} : A}{Ξ ⊢ \t{μα t} : \f{A}}$>

let r_name =
  <$\binaryRN{[\wc]}{Ξ ⊢ u : A}{Ξ ⊢ π : ¬A}{Ξ ⊢ \t{[π]u} : \f{B}}$>

let r_ax_bot =
  <$\unaryRN{Ax^⊥}{Ξ ⊢ B ⊂ A}{Ξ ⊢ \s{εα∈A(t∉A)} : ¬B}$>

let r_push =
  <$\ternaryRN{\wc·\wc}{Ξ ⊢ v : A}{Ξ ⊢ π : ¬B}{Ξ ⊢ C ⊂ \f{A⇒B}}
    {Ξ ⊢ \s{v·π} : ¬C}$>

let r_fram =
  <$\binaryRN{[\wc]\wc}{Ξ ⊢ t : \f{A⇒B}}{Ξ ⊢ π : ¬B}
    {Ξ ⊢ \s{[t]π} : ¬A}$>

let r_sum_i =
  <$\binaryRN{+_i}{Ξ ⊢ \t{v} : \f{A}}
    {Ξ ⊢ \t{Ck[v]} ∈ \f{[Ck : A]} ⊂ \f{B}}{Ξ ⊢ \t{Ck[v]} : B}$>

let r_sum_e =
  <$\binaryRN{+_e}{Ξ ⊢ \t{v} : \f{[(Ci : Ai) i∈I]}}
    {(Ξ ⊢ \t{ti[xi ≔ εxi∈Ai∧Ci[xi]≡v(ti∉C)]} : \f{C})_{i∈I}}
    {Ξ ⊢ \t{[v | (Ci[xi] → ti) i∈I]} : \f{C}}$>

let r_prod_i =
  <$\binaryRN{×_i}{Ξ ⊢ \t{{(li = vi) i∈I}} ∈ \f{{(li : Ai) i∈I}} ⊂ C}
    {(Ξ ⊢ \t{vi} : \f{Ai})_{i∈I}}{Ξ ⊢ \t{{(li = vi) i∈I}} : C}$>

let r_prod_e =
  <$\unaryRN{×_e}{Ξ ⊢ \t{v} : \f{{lk : A; ⋯}}} {Ξ ⊢ \t{v.lk} : A}$>

let r_ax_sub =
  <$\unaryRN{Ax_{⊂}}{(Ξ ⊢ ρ₁(χ) ≡ ρ₂(χ))_{χ∈FV(A)}}
    {Ξ ⊢ \t{t} : \f{Aρ₁} ⊂ \f{Aρ₂}}$>

let r_ax_gen =
  <$\unaryRN{Gen}{Ξ ⊢ A ⊂ B}{Ξ ⊢ \t{t} : A ⊂ B}$>

let r_arrow =
  <$\ternaryRN{{⇒} \hspace(1.0) \mathsize(4.0){w = \v{εx∈A₂(t x∉B₂)}}}
    {Ξ, w ≠ \v{□} ⊢ w ∈ \f{A₂} ⊂ \f{A₁}}
    {Ξ, w ≠ \v{□} ⊢ \t{t w} ∈ \f{B₁} ⊂ \f{B₂}}
    {Ξ ⊢ t ≡ v}
    {Ξ ⊢ \t{t} ∈ \f{A₁ ⇒ B₁} ⊂ \f{A₂ ⇒ B₂}}$>

let r_sum =
  <$\ternaryRN{+}{I₁ ⊂ I₂}
    {(Ξ ⊢ \t{(λx [x | Ci[xi] → xi]) t} ∈ \f{Ai} ⊂ \f{Bi})_{i∈I₁}}
    {Ξ ⊢ t ≡ v}
    {Ξ ⊢ \t{t} ∈ \f{[(Ci : Ai) i∈I₁]} ⊂ \f{[(Ci : Bi) i∈I₂]}}$>

let r_prod =
  <$\binaryRN{×}
    {(Ξ ⊢ \t{(λx x.li) t} ∈ \f{Ai} ⊂ \f{Bi})_{i∈I}}
    {Ξ ⊢ t ≡ v}
    {Ξ ⊢ \t{t} ∈ \f{{(li : Ai) i∈I}} ⊂ \f{{(li : Bi) i∈I}}}$>

let r_prod_ext1 =
  <$\ternaryRN{×_{ext}}{I₂ ⊂ I₁}
    {(Ξ ⊢ \t{(λx x.li) t} ∈ \f{Ai} ⊂ \f{Bi})_{i∈I₂}}
    {Ξ ⊢ t ≡ v}
    {Ξ ⊢ \t{t} ∈ \f{{(li : Ai) i∈I₁ ; ⋯}} ⊂ \f{{(li : Bi) i∈I₂ ; ⋯}}}$>

let r_prod_ext2 =
  <$\ternaryRN{×_{⊂}}{I₂ ⊂ I₁}
    {(Ξ ⊢ \t{(λx x.li) t} ∈ \f{Ai} ⊂ \f{Bi})_{i∈I₂}}
    {Ξ ⊢ t ≡ v}
    {Ξ ⊢ \t{t} ∈ \f{{(li : Ai) i∈I₁}} ⊂ \f{{(li : Bi) i∈I₂ ; ⋯}}}$>

let r_forall_l =
  <$\unaryRN{∀_l}
    {Ξ ⊢ \t{t} ∈ \f{A[χ≔C]} ⊂ \f{B}}
    {Ξ ⊢ \t{t} ∈ \f{∀χ^s A} ⊂ \f{B}}$>

let r_forall_r =
  <$\binaryRN{∀_r}
    {Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B[χ ≔ εχ∈s(t∉B)]}}
    {Ξ ⊢ v ≡ t}
    {Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{∀χ^s B}}$>

let r_exists_r =
  <$\unaryRN{∃_r}
    {Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B[χ≔C]}}
    {Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{∃χ^s B}}$>

let r_exists_l =
  <$\binaryRN{∃_l}
    {Ξ ⊢ \t{t} ∈ \f{A[χ ≔ εχ∈s(t∈A)]} ⊂ \f{B}}
    {Ξ ⊢ t ≡ v}
    {Ξ ⊢ \t{t} ∈ \f{∃χ^s A} ⊂ \f{B}}$>

let r_rest_l =
  <$\binaryRN{\restriction_l}
    {Ξ, u₁ ≡ u₂ ⊢ \t{t} ∈ \f{A} ⊂ \f{B}}
    {Ξ ⊢ v ≡ t}
    {Ξ ⊢ \t{t} ∈ \f{A ∧ u₁ ≡ u₂} ⊂ \f{B}}$>

let r_rest_r =
  <$\binaryRN{\restriction_r}
    {Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B}}
    {Ξ ⊢ u₁ ≡ u₂}
    {Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B ∧ u₁ ≡ u₂}}$>

let r_memb_l =
  <$\binaryRN{∈_l}
    {Ξ, t ≡ u ⊢ \t{t} ∈ \f{A} ⊂ \f{B}}
    {Ξ ⊢ t ≡ v}
    {Ξ ⊢ \t{t} ∈ \f{u ∈ A} ⊂ \f{B}}$>

let r_memb_r =
  <$\ternaryRN{∈_r}
    {Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B}}
    {Ξ ⊢ t ≡ u}
    {Ξ ⊢ t ≡ v}
    {Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{u ∈ B}}$>

(** Ordinal ordering rules. *)
let ord1 = <$\unaryR{i ≤ 0}{γ ⊢ \o{τ} ≤_i \o{τ}}$>
let ord2 = <$\unaryR{γ ⊢ τ ≤_{i+1} υ}{γ ⊢ \o{τ+1} ≤_i \o{υ}}$>
let ord3 = <$\unaryR{γ ⊢ τ ≤_{i-1} υ}{γ ⊢ \o{τ} ≤_i \o{υ+1}}$>
let ord4 =
  <$\unaryR{γ,τ ⊢ \o{τ} ≤_{i-1} \o{υ}}{γ,τ ⊢ \o{εθ<τ(t∈A)} ≤_i \o{υ}}$>
let ord5 =
  <$\unaryR{γ ⊢ \o{τ} ≤_i \o{υ}}{γ ⊢ \o{εθ<τ(t∈A)} ≤_i \o{υ}}$>

(** Subtyping rules for induction and coinductive types. *)
let r_mu_r_inf =
  <$\unaryRN{μ_{r,∞}}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B[X ≔ μ∞X B]}}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{μ∞X B}}$>

let r_nu_l_inf =
  <$\unaryRN{ν_{l,∞}}
    {γ; Ξ ⊢ \t{t} ∈ \f{A[X ≔ ν∞X A]} ⊂ \f{B}}
    {γ; Ξ ⊢ \t{t} ∈ \f{ν∞X A} ⊂ \f{B}}$>

let r_mu_r =
  <$\binaryRN{μ_r}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B[X ≔ μυX B]}}
    {γ ⊢ υ < τ}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{μτX B}}$>

let r_nu_l =
  <$\binaryRN{ν_l}
    {γ; Ξ ⊢ \t{t} ∈ \f{A[X ≔ νυX A]} ⊂ \f{B}}
    {γ ⊢ υ < τ}
    {γ; Ξ ⊢ \t{t} ∈ \f{ντX A} ⊂ \f{B}}$>

let r_mu_l =
  <$\binaryRN{μ_l}
    {γ,τ; Ξ ⊢ \t{t} ∈ \f{A[X ≔ μεθ<τ(t∈A[X ≔ μθX A])X A]} ⊂ \f{B}}
    {Ξ ⊢ v ≡ t}
    {γ; Ξ ⊢ \t{t} ∈ \f{μτX A} ⊂ \f{B}}$>

let r_nu_r =
  <$\binaryRN{ν_r}
    {γ,τ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B[X ≔ νεθ<τ(t∉B[X ≔ νθX B])X B]}}
    {Ξ ⊢ v ≡ t}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{ντX B}}$>

(* Ordinal restriction rules. *)
let r_ordrest_l =
  <$\binaryRN{\restriction_{l,κ}}
    {γ, γ₀; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B}}
    {Ξ ⊢ v ≡ t}
    {γ; Ξ ⊢ \t{t} ∈ \f{A ∧ γ₀} ⊂ \f{B}}$>

let r_ordrest_r =
  <$\binaryRN{\restriction_{r,κ}}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B}}
    {γ₀ ⊂ γ}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B ∧ γ₀}}$>

let r_ordimpl_l =
  <$\binaryRN{\inj_{l,κ}}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B}}
    {γ₀ ⊆ γ}
    {γ; Ξ ⊢ \t{t} ∈ \f{γ₀ ↪ A} ⊂ \f{B}}$>

let r_ordimpl_r =
  <$\unaryRN{\inj_{r,κ}}
    {γ, γ₀; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{B}}
    {γ; Ξ ⊢ \t{t} ∈ \f{A} ⊂ \f{γ₀ ↪ B}}$>

(* Rules for propagating ordinal restrictions. *)
let r_arrow_ord_i =
  <$\binaryRN{⇒_{i,κ}}{γ; Ξ ⊢ \t{λx t} ∈ \f{γ₀ ↪ (A ⇒ B)} ⊂ C}
    {γ, γ₀; Ξ ⊢ \t{t[x ≔ εx∈A(t∉B)]} : \f{B}}{γ; Ξ ⊢ \t{λx t} : C}$>

let r_sum_ord_e =
  <$\ternaryRN{+_{e,κ}}{γ; Ξ ⊢ \t{v} : A}
    {γ; Ξ ⊢ \t{v} ∈ A ⊆ \f{[(Ci : Ai) i∈I] ∧ γ₀}}
    {(γ, γ₀; Ξ ⊢ \t{ti[xi ≔ εxi∈Ai∧C[xi]≡v(ti∉C)]} : \f{C})_{i∈I}}
    {γ; Ξ ⊢ \t{[v | (Ci[xi] → ti) i∈I]} : \f{C}}$>
let r_sum_ord_e = mathsize 3.0 r_sum_ord_e
(* FIXME  FIXME  FIXME  FIXME  FIXME *)

(* Fixpoint rule. *)
let r_fix =
  <$\binaryRN{Y}
    {γ, γ₀; Ξ ⊢ \t{t[x≔λx Y(λr t,x)]} : \f{A⇒B}}
    {γ; Ξ ⊢ \t{λx Y(λr t,x)} ∈ \f{γ₀ ↪ (A⇒B)} ⊂ \f("C")}
    {γ; Ξ ⊢ \t{λx Y(λr t,x)} : \f{C}}$>

let typ_rs env =
  let env = resize_env 3.5 env in
  let rs =
    [ [ r_arrow_i ]
    ; [ r_ax ]
    ; [ r_arrow_e ; r_arrow_ee ]
    ; [ r_mu ; r_name ; r_ax_bot ]
    ; [ r_push ; r_fram ]
    ; [ r_prod_e ; r_prod_i ]
    ; [ r_sum_e ]
    ; [ r_sum_i ] ]
  in
  let rs = List.map (List.map (fun cs -> <<$\id(cs)$>>)) rs in
  List.map (List.map (fun cs -> draw_boxes env (boxify_scoped env cs))) rs

let sub_rs env =
  let env = resize_env 3.5 env in
  let rs =
    [ [ r_arrow ]
    ; [ r_sum ]
    ; [ r_prod ; r_ax_sub ]
    ; [ r_prod_ext1 ; r_ax_gen ]
    ; [ r_prod_ext2 ]
    (* quantifiers. *)
    ; [ r_forall_l ; r_forall_r ]
    ; [ r_exists_r ; r_exists_l ]
    (* restriction and membership. *)
    ; [ r_rest_l ; r_rest_r ]
    ; [ r_memb_l ; r_memb_r ] ]
  in
  let rs = List.map (List.map (fun cs -> <<$\id(cs)$>>)) rs in
  List.map (List.map (fun cs -> draw_boxes env (boxify_scoped env cs))) rs

let extra_sub_rs env =
  let env = env in
  let rs =
    [ [ r_mu_r_inf ; r_nu_l_inf ]
    ; [ r_mu_r ]
    ; [ r_nu_l ]
    ; [ r_mu_l ]
    ; [ r_nu_r ] ]
  in
  let rs = List.map (List.map (fun cs -> <<$\id(cs)$>>)) rs in
  List.map (List.map (fun cs -> draw_boxes env (boxify_scoped env cs))) rs

let extra_sub_ord_rs env =
  let env = env in
  let rs =
    [ [ r_ordrest_l ; r_ordrest_r ]
    ; [ r_ordimpl_l ; r_ordimpl_r ]
    ; [ r_arrow_ord_i ]
    ; [ r_sum_ord_e ]
    ; [ r_fix ] ]
  in
  let rs = List.map (List.map (fun cs -> <<$\id(cs)$>>)) rs in
  List.map (List.map (fun cs -> draw_boxes env (boxify_scoped env cs))) rs

let ordering_rs env =
  let env = env in
  let rs =
    [ [ ord1 ; ord2 ; ord3 ]
    ; [ ord4 ; ord5 ] ]
  in
  let rs = List.map (List.map (fun cs -> <<$\id(cs)$>>)) rs in
  List.map (List.map (fun cs -> draw_boxes env (boxify_scoped env cs))) rs

let typrules () =
  figure_here ~name:"typrules"
    ~caption:[tT "Typing rules for terms and stacks."] (dr typ_rs)

let subrules () =
  figure_here ~name:"subrules"
    ~caption:[tT "Local subtyping rules."] (dr sub_rs)

let extra_subrules () =
  figure_here ~name:"extrasubrules"
    ~caption:[tT "Local subtyping rules for inductive and coinductive types."]
      (dr extra_sub_rs)

let extra_ord_subrules () =
  figure_here ~name:"extraordsubrules"
    ~caption:[tT "Typing and subtyping rules for the handling of recursion."]
      (dr extra_sub_ord_rs)

let ordering_rules () =
  figure_here ~name:"orderingrules"
    ~caption:[tT "Rules of ordinal ordering."] (dr ordering_rs)

)

=> Introducing subtyping into the system \label("subtyping")

\begin{center}
\linesBefore(10)
\end{center}
(* *)
In this chapter, we reformulate the definition of our system to account for
subtyping. The main idea is to transform the typing rules that do not have
algorithmic contents into subtyping rules. For instance, quantifiers,
fixpoints, membership types and equality types will be handled using
subtyping.

=> Interests of subtyping

There is no denying that polymorphism and type abstraction are essential
features for programming in a generic way. They lead to programs that are
shorter, more modular, easier to understand and hence more reliable.
Although subtyping provides similar perspectives, it is considerably
less widespread among programming languages. Practical languages only rely
on limited forms of subtyping for their module system \cite("MacQueen1984"),
or for the use of polymorphic variants \cite("Garrigue1998"). Overall,
subtyping is useful for both product types (e.g., records or modules) and
sum types (e.g., polymorphic variants). It provides canonical injections
between a type and its subtypes. For example, the natural numbers may be
defined as a subtype of the integers.

The downside of subtyping is that it is difficult to incorporate in
complex systems like Haskell or OCaml. For example, OCaml
provides polymorphic variants \cite("Garrigue1998") for which complex
annotated types are inferred. For instance, one would expect the
following OCaml function to be given the type ##[`T | `F] → [`T | `F]##.
### OCaml
  let neg = function `T → `F | `F → `T
###
Indeed, the variance of the arrow type conveys enough information: ##neg##
can be applied to elements of any subtype of ##[`T | `F]## (e.g., ##[`T]##)
and produces elements of any supertype of ##[`T | `F]## (e.g.
##[`T | `F | `M]##). OCaml infers the type ##[<`T | `F] → [>`T | `F]##
in which subtypes and supertypes are explicitly tagged. This is not very
natural and hides a complex mechanism involving polymorphic type variables.
More discussion on the limitations of OCaml's polymorphic variants, can
be found in \cite("Castagna2016"), for example.

In this thesis, we will show that it is possible to design a practical
type system based on subtyping for our language. It allows for a rather
straight-forward implementation following the typing and subtyping rules
that will be given in the following sections. In particular, the typing
and subtyping procedures are directed by the syntax of terms and types
respectively. The ideas presented here were introduced in a joint work
of Christophe Raffalli and the author \cite("Lepigre2017").

=<

=> Symbolic witnesses and local subtyping

Several related technical innovations are required to include subtyping
into our system. In particular, we will need to generalise the usual
subtyping relation $A ⊂ B$ (meaning "$A$ is a subtype of $B$") using a
//local subtyping// relation $t ∈ A ⊂ B$. It will be interpreted as
"if $t$ has type $A$ then it also has type $B$". Usual subtyping is then
recovered using choice operators inspired from //Hilbert's Epsilon and
Tau functions// \cite("Hilbert1934"). In our system, the choice operator
$\v{εx∈A(t∉B)}$ denotes a value $v$ of type $A$ such that $\t{t[x≔v]}$
does not have type $B$. If no such term exists, then an arbitrary term
of type $A$ can be chosen. We can then take $\v{εx∈A(x∉B)} ∈ A ⊂ B$ as
a definition of $A ⊂ B$.
\begin{rem}
Of course, for the choice operator $\v{εx∈A(t∉B)}$ to be well-defined
we will need the interpretation of every type to be non-empty. It is the
case in \cite("Lepigre2017") as the model is based on Girard's
reducibility candidates \mcite(["Girard1972"; "Girard1989"]). Here,
we will use the special value $\v{□}$ as it is contained in the
interpretation of all types by construction. This is its very purpose.
\end{rem}

Choice operators can be used to replace the notion of free variables,
and hence suppress the need for typing contexts. The contexts will
then be limited to an equational context containing closed terms.
Intuitively, $\v{εx∈A(t∉B)}$ denotes a counterexample to the fact
that $\t{λx t}$ has type $\f{A⇒B}$. Consequently, we will use the
following rule for typing $λ$-abstractions.
\begin{center}
$ \unaryR{Ξ ⊢ \t{t[x≔εx∈A(t∉B)]} : B}
    {Ξ ⊢ \t{λxt} : \f{A⇒B}} $
\end{center}
It can be read as a proof by contradiction
as its premise is only valid when there is no value $v$ of type $A$ such
that $\t{t[x≔v]}$ does not have type $B$. The axiom rule is then
replaced by the following typing rule for choice operators.
\begin{center}
$ \axiomR{Ξ ⊢ \t{εx∈A(t∉B)} : A} $
\end{center}
Obviously, the same trick can be used for $μ$-variables and
$μ$-abstractions. As choice operators for values, choice
operators for stacks will always need to be interpreted
(even if there is no stack satisfying the property they carry).
As a consequence, we will need to make sure that the set of stacks
associated to each type contain at least one element.

The use of choice operators and the elimination of typing contexts
will play an essential role in the definition of our type system.
Indeed, they will allow us to handle quantifiers using our local
subtyping relation only. As a consequence, we will work with
syntax-directed typing rules and most of the work will be done
using subtyping.
(* *)
We will thus introduce two new type constructors $\f{εX(t∈A)}$ and
$\f{εX(t∉A)}$ corresponding to choice operators for picking a type
satisfying the denoted properties. For example, $\f{εX(t∉B)}$ is a
type such that the term $t$ does not have type $\f{B[X≔εX(t∉B)]}$.
Intuitively, $\f{εX(t∉B)}$ is a counter-example to the judgment
"$t$ has type $\f{∀X B}$". Hence, to show that $t$ has type
$\f{∀X B}$ it will be enough to show that it has type
$\f{B[X≔εX(t∉B)]}$. As a consequence, the introduction rule for
the universal quantifier is subsumed by the following local
subtyping rule.
\begin{center}
$ \binaryR{Ξ ⊢ t ∈ A ⊂ \f{B[X≔εX(t∉B)]}}{Ξ ⊢ t ≡ v}
          {Ξ ⊢ t ∈ A ⊂ \f{∀X B}} $
\end{center}
Note that it includes a premise stating that the term $t$ carried by
the judgments should be equivalent to a value. This corresponds to
the semantical value restriction condition in our new system with
subtyping.

In conjunction with local subtyping, choice operators allow the
derivation of many valid permutations of quantifiers and connectives.
For example, subtyping relations like
$$
  \f{∀X ∀Y A} ⊂ \f{∀Y ∀X A}
  \hspace(4.0)
  \f{{l₁ : ∀X A; l₂ : ∀X B}} ⊂ \f{∀X {l₁ : A; l₂ : B}}
$$
can be easily obtained thanks to our syntax-directed subtyping rules.
In particular, they do not include a transitivity rule, and this is a
good thing since such a rule could not be implemented. Indeed, it would
require the system to guess an intermediate type.
(* *)
Transitivity is generally admissible in subtyping systems.
In our system however, it is an open problem whether a form of
transitivity is admissible. However, type annotations of the form
$((t : A) : B) : C$ can always be used to decompose a proof of
$t : C$ into proofs of $t : A$, $t ∈ A ⊂ B$ and $t ∈ B ⊂ C$. Such
annotations are also required in the implementations of systems
having a transitivity rule. Indeed, without annotations the system
would need to guess the intermediate types $A$ and $B$.

=<
=> Typing and subtyping rules

We will now give the formal definition of our new type system
with subtyping. We will reuse some of the formalism given in
\chapter("typeSystem"), but modifications will be required. For
instance, we will need to extend the language of values, stacks
and formulas to include choice operators.
\begin{def}
We extend the language of formulas $\cal{F}$ with new
constructors $\f{εχ∈s(t∈A)}$ and $\f{εχ∈s(t∉A)}$ representing
choice operators. They will be made available in the syntax, and
will provide an alternative presentation of quantifiers. Note that
our system needs to be extended with the following two sorting
rules.
\begin{center}
$
  \binaryR{Σ ⊢ t : τ}{Σ, χ : s ⊢ A : ο}{Σ ⊢ \f{εχ∈s(t∈A)} : s}
  \hspace(4.0)
  \binaryR{Σ ⊢ t : τ}{Σ, χ : s ⊢ A : ο}{Σ ⊢ \f{εχ∈s(t∉A)} : s}
$
\end{center}
\linesAfter(0) (* FIXME hack. *)
\end{def}

To introduce value and stack witnesses into our system, we will
need to make a distinction between values, terms, stacks and
formulas that may contain value and stack witnesses and those
that may not.
\begin{def}
We extend the syntax of values with a new constructor
$\v{εx∈A(t∉B)}$, where $x∈\cal{V}_ι$ is a $λ$-variables,
$t∈Λ$ is a term and $A$, $B∈\cal{F}$ are propositions.
Similarly, the syntax of stacks is extended with a new
constructor $\s{εα∈A(t∉A)}$, where $α∈\cal{V}_σ$ is a
$μ$-variable, $t∈Λ$ is a term and $A∈\cal{F}$ is a
proposition. Note that our system needs to be extended
with the following two sorting rules.
\begin{center}
$
  \ternaryR{x:ι ⊢ A:ο}{x:ι ⊢ t:τ}{x:ι ⊢ B : ο}{Σ ⊢ \t{εx∈A(t∉B)}:ι}
  \hspace(4.0)
  \binaryR{α:σ ⊢ A:ο}{α:σ ⊢ t:τ}{Σ ⊢ \s{εα∈A(t∉A)}:σ}
$
\end{center}
It is important to note that no other variable than $x$ may be bound
in $A$, $t$ or $B$ in the first rule. Similarly, only $α$ can be
bound in $t$ and $B$ in the second one. These restrictions are
required for the definition of our semantics.
\end{def}
\begin{def}
We will refer to values, terms and stacks that may contain value
and stack witnesses as //raw// values, //raw// terms and //raw//
stacks. The corresponding sets will be denoted $Λ^{+}_ι$, $Λ^{+}$
and $Π^{+}$ respectively.
\end{def}

Before going into our new typing and subtyping rules, we will extend
the syntax of formulas one more time. Indeed, our current system (and
its semantics) does not allow for all the basic subtyping relations that
we could hope for. For instance, if $I₁ ⊆ I₂$ then it is possible to show
that $\f{[(Ci : Ai) i∈I₁]}$ is a subtype of $\f{[(Ci : Ai) i∈I₂]}$ in
the system. However, the corresponding relation on product types is
not satisfied by our semantics. Intuitively, the elements of the type
$\f{{(li:Ai) i∈I}}$ must of the form $\v{{(li = vi) i∈I}}$. In particular,
they cannot have additional record fields. One solution to this problem
would be to amend the semantics of product types. Instead, we will keep our
original, //strict// product type, and introduce another //extensible//
product type.
\begin{def}
The syntax of formulas $\cal{F}$ is extended with an //extensible product
type// constructors $\f{{(li : Ai) i∈I ; ⋯}}$. Our system again requires
a new sorting rule.
\begin{center}
$\unaryR{\{Σ ⊢ A_i : ο\}_{i∈I}}{Σ ⊢ \f{{(li:Ai)i∈I;⋯}} : ο}$
\end{center}
\linesAfter(0) (* FIXME hack. *)
\end{def}

We will now give the new typing and subtyping rules of our system, which
will contain three (and in fact four) new forms of judgments.
\begin{def}
A //general typing judgment// is a triple of an equational context
$Ξ$, a raw term $t∈Λ^+$ and a formula $A ∈ \cal{F}$ that is denoted
$Ξ ⊢ t : A$. A //general stack judgment// is a triple of an equational
context $Ξ$, a raw stack $π∈Π^+$ and a formula $A ∈ \cal{F}$ that is
denoted $Ξ ⊢ π : ¬A$. A //pointed subtyping judgment// is a quadruple
of an equational context $Ξ$, a raw term $t∈Λ^{+}$ and two formulas
$A$, $B ∈ \cal{F}$ that is denoted $Ξ ⊢ t ∈ A ⊂ B$. We will use the
notation $Ξ ⊢ A ⊂ B$ when the term $t$ is equal to $\v{εx∈A(x∉B)}$.
\end{def}

To keep track of the special value $\v{□}$ in our judgments, we will
use inequivalences of the form $v ≠ \v{□}$. They will be defined in
terms of an usual equivalence, so we do not need to extend our
definitions formally.
\begin{def}
Given a closed value $v ∈ Λ_ι^{∗}$ we will use the notation $v ≠ \v{□}$
for the syntactic equivalence $\t{(λx {}) v} ≡ \t{{}}$ in equational
contexts.
\end{def}
As show by the following lemma, this notation provides the right
intuition as it agrees with the semantics.
\begin{lem}\label("specialequiv")
Given a closed value $v ∈ Λ_ι^{∗}$ we have $\t{(λx {}) v} ≡ \t{{}}$
if and only if $v ≠ \v{□}$.
\begin{proof}
Let us first assume that $v ≠ \v{□}$ and show $\t{(λx {}) v} ≡ \t{{}}$.
Since $v$ is closed, it cannot be a $λ$-variable and so we can conclude
immediately using \theorem("cbvbeta"). For the other direction we show
the contrapositive so we assume $v = \v{□}$ and we show $\t{(λx {}) v}
\nequiv \t{{}}$. According to \theorem("boxbetared") we have
$\t{(λx {}) □} ≡ \t{□}$ and so it is enough to show
$\v{□} \nequiv \v{{}}$. This follows from \theorem("canonbox").
\end{proof}
\end{lem}

\begin{def}
A general typing judgment, general stack judgment or pointed subtyping
judgment is said to be valid if it can be derived using the rules of
\figRefs(["typrules" ; "subrules"]).
\end{def}
There is nothing too surprising about our new typing rules. Note
however that, in the case where our equivalence decision procedure
is unable to prove a premise of the form $Ξ ⊢ v ≡ t$ in a local
subtyping rule, one can always fallback to the ($Gen$) rule.

\Caml(let _ = typrules ()) (* NOTE can be moved *)

=<
=> Semantics of subtyping

We will now adapt our model to work with our new typing and subtyping
rules. The main problem that we need to solve is the interpretation of
raw terms, values and stacks. In particular, we need to provide an
interpretation to our choice operators. In \cite("Lepigre2017"), the
choice operator $\v{εx∈A(t∉B)}$ is interpreted using a value $v ∈ \vs{A}$
such that $\t{t[x≔v]}$ is in the semantics of $B$. In the case where
no such value exists, an arbitrary member of $\vs{A}$ is chosen. Here,
a crucial point is that the set $\vs{A}$ should not be empty. It is
the case here as by construction we have $\v{□} ∈ \vs{A}$ for every
proposition $A$. This special value $\v{□}$ will thus be understood
as an undefined value witness.
\Caml(let _ = subrules ()) (* NOTE can be moved *)

\begin{lem}\label("noboxred")
Let $p ∈ Λ×Π$ be a process such that $\v{□} ∉ p$. If there is $q ∈ Λ×Π$
such that $p ↠ q$ then $\v{□} ∉ q$.
\begin{proof}
Most reduction rules of $({↠})$ only build a new process using components
of the process $p$ being evaluated. Hence, they cannot make $\v{□}$ appear
it was not already present in $p$. The remaining rules are related to
binders, and obviously if $t$, $v$ and $π$ do not contain $\v{□}$, then
neither do $\f{t[x≔v]}$ or $\f{t[α≔π]}$.
\end{proof}
\end{lem}
Similarly, if a variable does not appear in a process then it cannot appear
during reduction. In particular, the evaluation of a closed process never
produces an open process.

In the semantics, raw values, raw terms and raw stacks will be interpreted
using values, terms and stacks with the same structure. The underlying
choice operators will thus be replaced by elements of the corresponding
syntactic category.
\begin{def}
Given a raw value $v ∈ Λ_ι^{+}$ (resp. raw term $t ∈ Λ^{+}$, raw stack
$π ∈ Π^+$), we denote $⟦v⟧ ∈ Λ_ι$ (resp. $⟦t⟧ ∈ Λ$, $⟦π⟧ ∈ Π$) its
semantical interpretation. It is defined inductively as follows.
\begin{center}
\diagram(
let contents =
  let line syn s1 s2 = [<$ \syn(s1) $> ; <$ = $> ; <$ \syn(s2) $>] in
  let spec syn s  n = [<$ \syn(s) $> ; <$ = $> ; n] in
  two_cols
  [ line v "⟦x⟧"                  "x"
  ; line v "⟦λx t⟧"               "λx ⟦t⟧"
  ; line v "⟦C[v]⟧"               "C[⟦v⟧]"
  ; line v "⟦□⟧"                  "□"
  ; line t "⟦a⟧"                  "a"
  ; line t "⟦t u⟧"                "⟦t⟧ ⟦u⟧"
  ; line t "⟦v.lk⟧"               "⟦v⟧.lk"
  ; line t "⟦Y(t,v)⟧"             "Y(⟦t⟧,⟦v⟧)"
  ; line t "⟦R(v,t)⟧"             "R(⟦v⟧,⟦t⟧)"
  ; line s "⟦α⟧"                  "α"
  ; line s "⟦v·π⟧"                "⟦v⟧·⟦π⟧"
  ; line s "⟦[t]π⟧"               "[⟦t⟧]⟦π⟧"
  ; line v "⟦{(li=vi)i∈I}⟧"       "{(li=⟦vi⟧)i∈I}"
  ; spec v "⟦εx∈A(t∉B)⟧"  <$ v∈{\vs{A[x≔v]} ∖ \{\v{□}\}} \st \t{⟦t[x≔v]⟧}∉\ts{B} $>
  ; spec v "⟦εx∈A(t∉B)⟧"  <$ \v{□} \hspace(0.4) otherwise $>
  ; line t "⟦μα t⟧"               "μα ⟦t⟧"
  ; line t "⟦[π]t⟧"               "[⟦π⟧] ⟦t⟧" 
  ; line t "⟦[v|(Ci[xi]→ti)i∈I]⟧" "[⟦v⟧|(Ci[xi]→⟦ti⟧)i∈I]"
  ; line t "⟦δ(v,w)⟧"             "δ(⟦v⟧,⟦w⟧)"
  ; line s "⟦ε⟧"                  "ε"
  ; spec s "⟦εα∈A(t∉A)⟧"  <$ π∈\ss{A[α≔π]} \st \t{⟦t[α≔π]⟧}∉\ts{B} $>
  ; spec s "⟦εα∈A(t∉A)⟧"  <$ \s{[□]ε} \hspace(0.4) otherwise $> ]
let _ = array [`East; `Main; `West; `East; `Main; `West] contents
          ~horizontal_padding:(fun n -> if n = 3 then 2.0 else 1.0)
          ~vertical_padding:(fun n -> 2.0)
)
\end{center}
\end{def}

It is important to note that, from now on, raw values, raw terms and raw
stacks may appear in types of any sort. However, up to the interpretation
of such raw syntactic elements, the semantics of our types will remain
the same as in \chapter("typeSystem"). Indeed, we will consider that a
raw value, raw term or raw stack is equal to its interpretation (and thus
to a value, term and stack respectively).
(* *)
We will however need to account for witnesses of the form $\f{εχ∈s(t∈A)}$
and $\f{εχ∈s(t∉A)}$ in their semantical interpretation. Intuitively, these
witnesses will be understood as formulas of the corresponding sort
satisfying the denoted property.
\begin{def}
We extend the definition of the interpretation of types (\defRef("typesem"))
in such a way that:
\begin{itemize}
\item $\vs{εχ∈s(t∈A)} = Φ$ such that $Φ ∈ ⟦s⟧$ and, if possible,
      $\t{⟦t⟧} ∈ \ts{A[χ≔Φ]}$,
\item $\vs{εχ∈s(t∉A)} = Φ$ such that $Φ ∈ ⟦s⟧$ and, if possible,
      $\t{⟦t⟧} ∉ \ts{A[χ≔Φ]}$.
\end{itemize}
Note that for every sort $s ∈ \cal{S}$ it is easy to see that $⟦s⟧ ≠ ∅$.
As a consequence, the interpretation of a type is always well-defined.
\end{def}
\begin{rem}
Although this is not explicitly mentioned, the interpretation of our choice
operators should be compatible with the definition of $({≡})$. For instance,
if $\t{⟦t⟧} ≡ \t{⟦u⟧}$ then we require $\t{⟦εx∈A(t∉B)⟧} = \t{⟦εx∈A(u∉B)⟧}$
(and similarly for the other forms of choice operators). This is possible
since $\t{⟦t[x≔v]⟧} ∈ \ts{B}$ if and only if $\t{⟦u[x≔v]⟧} ∈ \ts{B}$ as the
interpretation of our types is closed under $({≡})$. Note that this means
that we will also have $\t{⟦εx∈A(t∉B)⟧} = \t{□}$ if and only if
$\t{⟦εx∈A(u∉B)⟧} = \t{□}$ since the interpretation of our types is closed
under $({≡})$.
\end{rem}
\begin{def}
We also extend \defRef("typesem") with an interpretation for the extensible
product type. It is defined as follows.
\begin{center}
\linesBefore(2) (* FIXME HACK *)
$\vs{{(li:Ai) i∈I;⋯}} = \{\v{{(li = vi) i∈K}} \| {I ⊆ K}
    ∧ {∀i∈I, \v{vi} ∈ {\vs{Ai} ∖ \{\v{□}\}}} \} ∪ \{\v{□}\}$
\end{center}
\end{def}

We will now given the interpretation of our different forms of judgments
in the semantics, and prove the adequacy of the semantics with respect to
the typing rules given in \figRefs(["typrules" ; "subrules"]).

\begin{def}
Let $t ∈ Λ^{+}$ be a raw term, $π ∈ Π^{+}$ be a raw stack and $A$,
$B ∈ \cal{F}$ be two types. We will write $t ⊩ A$ if $\t{⟦t⟧} ∈ \ts{A}$,
$π ⊩ A$ if $\s{⟦π⟧} ∈ \ss{A}$ and $t ⊩ A ⊆ B$ if $t ⊩ A$ implies $t ⊩ B$.
\end{def}

\begin{lem}\label("subtypingincl")
Let $A$, $B ∈ \cal{F}$ be two types such that $\t{εx∈A(x∉B)} ⊩ A ⊂ B$. In
this case we have $\vs{A} ⊆ \vs{B}$.
\begin{proof}
We proceed by case on the definition of $v = \t{⟦εx∈A(x∉B)⟧}$.
If $v ≠ \v{□}$ then we have $v ∈ \vs{A}$ and $v ∉ \ts{B}$. This
is a contradiction since $v ∉ \vs{B}$ by \theorem("orthosimple").
(* *)
If $v = \v{□}$ then for all $w ∈ {\vs{A} ∖ \{\v{□}\}}$ we have $w ∈ \ts{B}$
and $w ∈ \vs{B}$ thanks to \theorem("main"). Moreover, $\v{□} ∈ \vs{A}$ and
$\v{□} ∈ \vs{B}$ so we indeed have $\vs{A} ⊆ \vs{B}$.
\end{proof}
\end{lem}
\begin{thm}\label("fulladequacy")
Let $Ξ$ be an equational context, $A$, $B ∈ \cal{F}$ be closed types and
$t ∈ Λ^{+}$ be a raw term. If for all $(\t{t₁},\t{t₂}) ∈ Ξ$ the equivalence
$\t{⟦t₁⟧} ≡ \t{⟦t₁⟧}$ holds then we have the following.
\begin{itemize}
\item If $Ξ ⊢ t : A$ is valid then we have $t ⊩ A$. Moreover, if $t$ is
      a value then $\t{⟦t⟧} ≠ \v{□}$.
\item If $Ξ ⊢ π : ¬A$ is valid then we have $π ⊩ A$.
\item If $Ξ ⊢ t ∈ A ⊂ B$ is valid then we have $t ⊩ A ⊂ B$.
\end{itemize}
\begin{proof}
We do a proof by induction on the structure of the proof of $Ξ ⊢ t : A$,
the proof of $Ξ ⊢ π : ¬A$ and the proof of $Ξ ⊢ t ∈ A ⊆ B$ respectively.
We consider the last rules used in the proof.
\begin{itemize}
\item In the case of the ($⇒_i$) rule, we need to show that $\t{λx t}⊩C$.
  According to the first induction hypothesis, it is enough to show
  $\t{λx t} ⊩ \f{A ⇒ B}$. Let us now suppose that there is a value
  $v ∈ {\vs{A} ∖ \{\v{□}\}}$ such that $\t{⟦t[x≔v]⟧} ∉ \ts{B}$. In this
  case we get a contradiction with our induction hypothesis since we must
  have $\t{⟦εx∈A(x∉B)⟧} ≠ \v{□}$ and $\t{⟦t[x≔εx∈A(x∉B)]⟧} ∉ \ts{B}$. As
  a consequence, we know that $\t{⟦t[x≔v]⟧} ∈ \ts{B}$ for all
  $v ∈ {\vs{A} ∖ \{\v{□}\}}$, which exactly means that $\v{⟦λx t⟧} ∈
  \vs{A⇒B}$. We can thus conclude using \theorem("orthosimple").
  \begin{center}
    $\id(r_arrow_i)$
  \end{center}

\item In the case of the ($⇒_e$) rule, we need to show that $\t{t u} ⊩ B$,
  which is the same as $\t{⟦t⟧ ⟦u⟧} ∈ \ts{B}$. We thus take $π ∈ \ss{B}$
  and we show that $\p{⟦t⟧ ⟦u⟧ ∗ π} ∈ \dbot$. Since $\dbot$ is
  $({↠})$-saturated, it is enough to show $\p{⟦u⟧ ∗ [⟦t⟧]π} ∈ \dbot$. As
  $⟦u⟧ ∈ \ts{A}$ by our second induction hypothesis, we will prove
  that $\s{[⟦t⟧]π} ∈ \ss{A}$. We thus take $v ∈ \vs{A}$ and show that we
  have $\p{v ∗ [⟦t⟧]π} ∈ \dbot$.
  (* *)
  If $v = \v{□}$ then we have $\p{□ ∗ [⟦t⟧]π} ↠ \p{□ ∗ π}$ and since
  $\dbot$ is $({↠})$-saturated it is enough to show $\p{□∗π} ∈ \dbot$,
  which is immediate since $π ∈ \ss{B}$ and $\v{□} ∈ \vs{B}$.
  (* *)
  Now, if $v ≠ \v{□}$ then $\p{v ∗ [⟦t⟧]π} ↠ \p{⟦t⟧ ∗ v·π}$ and as $\dbot$
  is $({↠})$-saturated it is enough to show $\p{⟦t⟧ ∗ v·π} ∈ \dbot$. Since
  $⟦t⟧ ∈ \ts{A ⇒ B}$ according to the first induction hypothesis, we only
  have to show that $\s{v·π} ∈ \ts{A⇒B}$ so we take $\v{w} ∈ \vs{A⇒B}$ and
  show that $\p{w ∗ v·π} ∈ \dbot$.
  (* *)
  If $w = \v{□}$ then $\p{□∗v·π} ↠ \p{□∗π}$ and it is enough to show
  $\p{□∗π}∈\dbot$ as $\dbot$ is $({↠})$-saturated. This is immediate
  since $π ∈ \ss{B}$ and $\v{□} ∈ \vs{B}$.
  (* *)
  If $w = \v{λx f}$ then $\p{λx f ∗ v·π} ↠ \p{f[x ≔ v] ∗ π}$ and it
  is enough to show $\p{f[x ≔ v] ∗ π} ∈ \dbot$ since $\dbot$ is
  $({↠})$-saturated. As $\s{π} ∈ \ss{B}$ it only remains to show
  $\t{f[x ≔ v]} ∈ \ts{B}$, but this is true by definition of
  $\vs{A ⇒ B}$ since $\v{v} ∈ {\vs{A} ∖ \{\v{□}\}}$.
  \begin{center}
    $\id(r_arrow_e)$
  \end{center}

\item In the case of the ($Ax$) rule, we need to $\t{εx∈A(t∉B)} ⊩ C$. Using
  the induction hypothesis, it is enough to show $\t{εx∈A(t∉B)} ⊩ A$.
  Moreover, according to \lemma("orthosimple") we only need to prove
  $\v{⟦εx∈A(t∉B)⟧} ∈ \vs{A}$, which follows by definition since
  $\v{□} ∈ \vs{A}$. Moreover, we obtain $\v{⟦εx∈A(t∉B)⟧} ≠ \v{□}$
  using the right premise with \lemma("specialequiv").
  \begin{center}
    $\id(r_ax)$
  \end{center}

\item In the case of the ($⇒_{e,{∈}}$) rule, we need to show that
  $\t{t u} ⊩ B$, which is the same as $\t{⟦t⟧ ⟦u⟧} ∈ \ts{B}$. We thus take
  $π ∈ \ss{B}$ and we show $\p{⟦t⟧ ⟦u⟧ ∗ π} ∈ \dbot$. Since $\dbot$ is
  $({↠})$-saturated, it is enough to show $\p{⟦u⟧ ∗ [⟦t⟧]π} ∈ \dbot$. Now,
  as our pole is $({≡})$-extensional and we know that $\t{⟦u⟧} ≡ \t{⟦v⟧}$
  for a value $v$, it is enough to show that $\p{⟦v⟧ ∗ [⟦t⟧]π} ∈ \dbot$.
  (* *)
  If $\v{⟦v⟧} = \v{□}$ then we can conclude as for the ($⇒_e$) rule and
  otherwise we can show $\p{⟦t⟧ ∗ ⟦v⟧·π} ∈ \dbot$ as $\dbot$ is
  $({↠})$-saturated. As $⟦t⟧ ∈ \ts{u∈A ⇒ B}$ by our first induction
  hypothesis, we only need to show $\s{⟦v⟧·π} ∈ \ss{u∈A ⇒ B}$. We thus
  take a value $\v{w} ∈ \vs{u∈A ⇒ B}$ and show $\p{w ∗ ⟦v⟧·π} ∈ \dbot$.
  If $\v{w} = \v{□}$ then we can conclude as for the ($⇒_e$) rule. If
  $\v{w} = \v{λx f}$ then we can again take a reduction step and show
  that $\p{f[x≔⟦v⟧] ∗ π} ∈ \dbot$, for which it is enough to show
  $\t{f[x≔⟦v⟧]} ∈ \vs{B}$. To conclude using the definition of
  $\vs{u∈A ⇒ B}$ we need to show $\t{⟦v⟧} ∈ {\vs{u∈A} ∖ \{\v{□}\}}$.
  Since we have $\t{⟦v⟧} ≠ \v{□}$ and $\t{⟦u⟧} ≡ \t{⟦v⟧}$ we only need
  to show $\t{⟦v⟧} ∈ \vs{A}$. Using \theorem("main") it is enough to
  show $\t{⟦v⟧} ∈ \ts{A}$, which follows from \theorem("poleext") as
  $⟦u⟧ ∈ \ts{A}$ by our second induction hypothesis since
  $\t{⟦u⟧} ≡ \t{⟦v⟧}$.
  \begin{center}
    $\id(r_arrow_ee)$
  \end{center}

\item In the case of the ($μ$) rule, we need to show that $\t{μαt} ⊩ A$,
  which is the same as $\t{μα⟦t⟧} ∈ \ts{A}$. We thus take $π ∈ \ss{A}$
  and show $\p{μα⟦t⟧ ∗ π} ∈ \dbot$. Since $\dbot$ is $({↠})$-saturated,
  it is enough to show $\p{⟦t⟧[α≔π] ∗ π} = \p{⟦t[α≔π]⟧ ∗ π} ∈ \dbot$ and
  as $π ∈ \ss{A}$ we only need to show $\t{⟦t[α≔π]⟧} ∈ \ts{A}$.
  (* *)
  Let us now suppose that there is a stack $\s{ξ} ∈ \ss{A}$ such that
  $\t{⟦t[α≔ξ]⟧} ∉ \ts{A}$. In this case we can assume that we have
  $ξ = \t{⟦εα∈A(t∉A)⟧}$ but this contradicts the induction hypothesis
  which tells us that $\t{⟦t[α≔εα∈A(t∉A)]⟧} ∈ \ts{A}$. As a consequence,
  we have $\t{⟦t[α≔ξ]⟧} ∈ \ts{A}$ for all $ξ ∈ \ss{A}$. In particular,
  this is true for $ξ = π$.
  \begin{center}
    $\id(r_mu)$
  \end{center}

\item In the case of the ($[\wc]$) rule, we need to show that $\t{[π]u}
  ⊩ B$, which is the same as $\t{[⟦π⟧]⟦u⟧} ∈ \ts{B}$. We thus take
  $ξ ∈ \ss{B}$ and show that $\p{[⟦π⟧]⟦u⟧ ∗ ξ} ∈ \dbot$. As $\dbot$ is
  $({↠})$-saturated, it is enough to show $\p{⟦u⟧ ∗ ⟦π⟧} ∈ \dbot$ but
  this is immediate since we have $\t{⟦u⟧} ∈ \ts{A}$ and $\s{⟦π⟧} ∈
  \ss{A}$ by induction hypothesis.
  \begin{center}
    $\id(r_name)$
  \end{center}

\item In the case of the ($Ax^⊥$) rule, we need to show that
  $\s{εα∈A(t∉A)} ⊩ B$, which is the same as $\s{⟦εα∈A(t∉A)⟧} ∈ \ss{B}$.
  By induction hypothesis, we know that $\t{εx∈B(x∉A)}⊩B⊂A$ and thus we
  can apply \lemma("subtypingincl") to get $\vs{B} ⊆ \vs{A}$. Using
  \lemma("orthoinclstack") we then obtain $\ss{A} ⊆ \ss{B}$ and thus
  it is enough to show $\s{⟦εα∈A(t∉A)⟧} ∈ \ss{A}$. We now reason by
  case on the definition of $\s{⟦εα∈A(t∉A)⟧}$. It is either defined
  to be a stack in $π ∈ \ss{A}$ (with some properties) in which case
  we can conclude immediately, or it is defined to be the stack
  $\s{[□]ε}$. In this second case we take $v ∈ \vs{A}$ and show
  $\p{v∗[□]ε} ∈ \dbot$. If $v = \v{□}$ then we have
  $\p{□∗[□]ε} ↠ \p{□∗ε}$ and otherwise we have $\p{v∗[□]ε} ↠
  \p{□∗v·ε} ↠ \p{□∗ε}$. We can then conclude since
  $\dbot$ is $({↠})$-saturated and $\p{□∗ε} ∈ \dbot$.
  \begin{center}
    $\id(r_ax_bot)$
  \end{center}

\item In the case of the ($\wc·\wc$) rule, we need to show that
  $\s{v·π} ⊩ C$, which is the same as $\s{⟦v⟧·⟦π⟧} ∈ \ss{C}$.
  Using \lemmas(["orthoinclstack" ; "subtypingincl"]) with the
  third induction hypothesis we have $\ss{A⇒B} ⊆ \ss{C}$. It
  is hence enough to show $\s{⟦v⟧·⟦π⟧} ∈ \ss{A⇒B}$, so we take
  $\v{w} ∈ \vs{A⇒B}$ and show $\p{w ∗ ⟦v⟧·⟦π⟧} ∈ \dbot$.
  If $\v{w} = \v{□}$ then it is enough to show $\p{□ ∗ ⟦π⟧} ∈ \dbot$
  as $\dbot$ is $({↠})$-saturated. This is immediate since
  $\s{⟦π⟧} ∈ \ss{B}$ by the second induction hypothesis and
  $\v{□} ∈ \vs{B}$. If $\v{w} = \v{λx f}$ then it is enough to show
  that $\p{f[x≔⟦v⟧] ∗ ⟦π⟧} ∈ \dbot$ as $({↠})$-saturated. Using the
  second induction hypothesis, we only need to show $\t{f[x≔⟦v⟧]} ∈
  \ts{B}$. As $\v{⟦v⟧} ∈ \ts{A}$ and $\v{⟦v⟧} ≠ \v{□}$ by our first
  induction hypothesis conclude by definition of $\vs{A⇒B}$ using
  \theorem("main").
  \begin{center}
    $\id(r_push)$
  \end{center}

\item In the case of the ($[\wc]\wc$) rule, we need to show that
  $\s{[t]π} ⊩ A$, which is the same as $\s{[⟦t⟧]⟦π⟧} ∈ \ss{A}$.
  We thus take $v ∈ \vs{A}$ and show $\p{v ∗ [⟦t⟧]⟦π⟧} ∈ \dbot$.
  If $v = \v{□}$ we have $\p{□∗[⟦t⟧]⟦π⟧} ↠ \p{□∗⟦π⟧}$ and since
  $\dbot$ is $({↠})$-saturated we only need to show $\p{□∗⟦π⟧} ∈
  \dbot$. This is immediate as $\s{⟦π⟧} ∈ \ss{B}$ by our second
  induction hypothesis and $\v{□} ∈ \vs{B}$. If $\v{v} ≠ \v{□}$
  then we have $\p{v∗[⟦t⟧]⟦π⟧} ↠ \p{⟦t⟧ ∗ v·⟦π⟧}$ and since
  $\dbot$ is $({↠})$-saturated, it is enough to show
  $\p{⟦t⟧ ∗ v·⟦π⟧} ∈ \dbot$. By the first induction hypothesis
  we have $\t{⟦t⟧} ∈ \ts{A⇒B}$ so we only need to show
  $\s{v·⟦π⟧} ∈ \ss{A⇒B}$. This can be done as in the proof of the
  previous case.
  \begin{center}
    $\id(r_fram)$
  \end{center}

\item In the case of the ($×_e$) rule, we need to show that $\t{v.lk} ⊩ A$,
  which is the same as $\t{⟦v⟧.lk} ∈ \ts{A}$. We thus take $π ∈ \ss{A}$ and
  show that $\p{⟦v⟧.lk ∗ π} ∈ \dbot$. By induction hypothesis, we know that
  $\v{⟦v⟧} ∈ \ts{{lk:A;⋯}}$ and that $\v{⟦v⟧} ≠ \v{□}$. Moreover, using
  \theorem("main") we obtain $\v{⟦v⟧} ∈ \vs{{lk:A;⋯}}$ and thus
  $\v{⟦v⟧} = \v{{(li = wi) i∈I}}$ with $k ∈ I$ and $\v{vk} ∈ \vs{A}$.
  As a consequence we only need to prove $\p{wk ∗ π} ∈ \dbot$ since $\dbot$
  is $({↠})$-saturated. This is immediate as $\v{wk} ∈ \vs{A}$ and
  $π ∈ \ss{A}$.
  \begin{center}
    $\id(r_prod_e)$
  \end{center}

\item In the case of the ($×_i$) rule, we need to show $\t{{(li = vi) i∈I}}
  ⊩ C$. Using the first induction hypothesis, it is enough to show that
  $\t{{(li = ⟦vi⟧) i∈I}} ∈ \vs{{(li : Ai) i∈I}}$. By definition, we need to
  show that $\v{⟦vi⟧} ∈ {\vs{Ai} ∖ \{\v{□}\}}$ for all $i ∈ I$. This
  follows by \theorem("main") using the induction hypotheses.
  \begin{center}
    $\id(r_prod_i)$
  \end{center}

\item In the case of the ($+_e$) rule, we need to show
  $\t{[v | (Ci[xi] → ti) i∈I]} ⊩ \f{C}$, which is the same as
  $\t{[⟦v⟧ | (Ci[xi] → ⟦ti⟧) i∈I]} ∈ \ts{C}$. We thus take a stack
  $π ∈ \ss{C}$ and show that $\p{[⟦v⟧ | (Ci[xi] → ⟦ti⟧) i∈I] ∗ π} ∈ \dbot$.
  Using the first induction hypothesis (together with \theorem("main")) we
  learn that $\t{⟦v⟧} ∈ \vs{[(Ci : Ai) i∈I]}$ and that $\v{⟦v⟧} ≠ \v{□}$.
  As a consequence, $\t{⟦v⟧} = \t{Ck[wk]}$ for some $k ∈ I$ and $\v{wk} ∈
  {\vs{Ai} ∖ \{\v{□}\}}$. As $\dbot$ is $({↠})$-saturated we only need
  to show $\p{⟦tk⟧[xk≔wk] ∗ π} = \p{⟦tk[xk≔wk]⟧ ∗ π} ∈ \dbot$.
  (* *)
  Let us assume that it is false and find a contradiction. Since $\v{wk} ∈
  {\vs{Ai} ∖ \{\v{□}\}}$ and $\t{⟦v⟧} = \t{Ck[wk]}$ we have
  $\v{wk} ∈ {\vs{Ai∧Ck[wk]≡v} ∖ \{\v{□}\}}$. As a consequence
  $\t{⟦εxk∈Ak∧C[xk]≡v(tk∉C)⟧} ≠ \v{□}$ since $\v{wk}$ is a possible
  definition for the witness. This contradicts the induction hypothesis
  since it implies $\t{⟦tk[xk≔εxk∈Ak∧C[xk]≡v(tk∉C)]⟧} ∉ \ts{C}$.
  \begin{center}
    $\id(r_sum_e)$
  \end{center}

\item In the case of the ($+_i$) rule, we need to show $\t{Ck[v]} ⊩ B$.
  Using the second induction hypothesis and \lemma("orthosimple"), it is
  enough to show $\t{Ck[⟦v⟧]} ∈ \vs{[Ck:A]}$. By definition, it is enough
  to show $\v{⟦v⟧} ∈ {\vs{A} ∖ \{\v{□}\}}$ which follows from the first
  induction hypothesis and \theorem("main").
  \begin{center}
    $\id(r_sum_i)$
  \end{center}

\item In the case of the ($Ax_{⊂}$) rule, we need to show $t ⊩ \f{Aρ₁} ⊂
  \f{Aρ₂}$. It is enough to show $\vs{Aρ₁} = \vs{Aρ₂}$ since in this case
  we will have $\ts{Aρ₁} = \ts{Aρ₂}$ which implies our goal. For every
  $λ$-variable or term variable $χ ∈ FV(A)$ we have $⟦ρ₁(χ)⟧ ≡ ⟦ρ₂(χ)⟧$.
  As a consequence, we can conclude with a simple proof by induction using
  \theorems(["fullextval" ; "fullextterm"]) to substitute one variable at
  a time.
  \begin{center}
    $\id(r_ax_sub)$
  \end{center}

\item In the case of the ($Gen$) rule, we need to show that $t ⊩ A ⊂ B$.
  Using the induction hypothesis with \lemma("subtypingincl") we obtain
  $\vs{A} ⊆ \vs{B}$, and we can thus conclude using \lemma("orthoincl").
  \begin{center}
    $\id(r_ax_gen)$
  \end{center}

\item In the case of the ($⇒$) rule, we need to show that $t ⊩ \f{A₁⇒B₁} ⊂
  \f{A₂⇒B₂}$. We thus assume $\t{⟦t⟧} ∈ \ts{A₁⇒B₁}$ and show that we have
  $\t{⟦t⟧} ∈ \ts{A₂⇒B₂}$. Now, as $\dbot$ is $({≡})$-extensional and
  $\t{⟦v⟧} ≡ \t{⟦t⟧}$ for some value $v$, we know that $\t{⟦v⟧} ∈
  \ts{A₁⇒B₁}$ and we only have to show that $\t{⟦v⟧} ∈ \ts{A₂⇒B₂}$. With
  \theorem("main") we even have $\t{⟦v⟧} ∈ \vs{A₁⇒B₁}$ and we can show
  $\t{⟦v⟧} ∈ \vs{A₂⇒B₂}$. If $\v{⟦v⟧} = \v{□}$ then this is immediate
  as we have $\v{□} ∈ \vs{A₂⇒B₂}$ by definition. Let us now suppose that
  $\t{⟦v⟧} = \t{λx f}$ and that for all $w ∈ {\vs{A₁} ∖ \{\v{□}\}}$ we have
  $\t{f[x≔w]} ∈ \ts{B₁}$.
  (* *)
  If we have $\t{⟦t⟧ w} ∈ \ts{B₂}$ for all $w∈{\vs{A₂} ∖ \{\v{□}\}}$ then,
  since we have $\t{⟦t⟧} ≡ \t{λx f}$, we can use \theorems(["poleext" ;
  "fullextterm"]) to get $\t{(λx f) w} ∈ \ts{B₂}$. We can then use
  \theorem("cbvbeta") to obtain $\t{f[x≔w]} ∈ \ts{B₂}$ for the same
  reason. This exactly means that we have $\t{⟦v⟧} = \t{λx f} ∈ \vs{A₂⇒B₂}$.
  (* *)
  Finally, let us suppose that $\t{⟦t⟧ w} ∉ \ts{B₂}$ for some value
  $w ∈ {\vs{A₂} ∖ \{\v{□}\}}$. We can assume that $w = \t{⟦εx∈A₂(t x∉B₂)⟧}$
  and thus the first induction hypothesis gives us $w ∈ \vs{A₁}$. We then
  obtain that $\t{f[x≔w]} ∈ \ts{B₁}$ by definition of $\vs{A₁⇒B₁}$.
  Now, using again \theorems(["cbvbeta" ; "fullextterm"]) we obtain
  $\t{f[x≔w]} ≡ \t{⟦t⟧ w}$ and thus we get a contradiction with the
  second induction hypothesis.
  \begin{center}
    $\fit(r_arrow)$
  \end{center}

\item In the case of the ($+$) rule, we need to show $t ⊩ \f{[(Ci:Ai) i∈I₁]}
  ⊂ \f{[(Ci:Bi) i∈I₂]}$. As in the case of the ($⇒$) rule, we know that
  $\t{⟦t⟧} ≡ \t{⟦v⟧}$ so we can assume that we have
  $\t{⟦v⟧} ∈ \vs{[(Ci:Ai) i∈I₁]}$ and show that
  $\t{⟦v⟧} ∈ \vs{[(Ci:Bi) i∈I₂]}$. If $\v{⟦v⟧} = \v{□}$ then the proof is
  trivial as for the ($⇒$) rule. As a consequence, we may assume that
  $\v{⟦v⟧} = \v{Ck[w]}$ for some $k ∈ I₁$ and $\v{w} ∈ {\vs{Ak} ∖
  \{\v{□}\}}$. Thus, we
  only need to show that $\v{w} ∈ \vs{Bk}$. Let us now consider
  the term $\t{⟦(λx[x|Ck[xk]→xk]) t⟧} = \t{(λx[x|Ck[xk]→xk]) ⟦t⟧}$.
  As we have $\t{⟦t⟧} ≡ \t{⟦v⟧} = \t{Ck[w]}$, we know
  $\t{(λx[x|Ck[xk]→xk]) ⟦t⟧} ≡ \t{(λx[x|Ck[xk]→xk]) Ck[w]}$.
  Using \theorems(["cbvbeta" ; "equivtrivial"]) we even obtain
  $\t{(λx[x|Ck[xk]→xk]) ⟦t⟧} ≡ \t{w}$. We can hence conclude using
  the induction hypothesis, the $({≡})$-extensionality of the pole
  and \theorem("main").
  \begin{center}
    $\id(r_sum)$
  \end{center}

\item In the case of the ($×$) rule, we need to show
  $t ⊩ \f{{(li : Ai) i∈I}} ⊂ \f{{(li : Bi) i∈I}}$. As in the case of
  the ($⇒$) rule, we know that $\t{⟦t⟧} ≡ \t{⟦v⟧}$ so we can assume that
  we have $\t{⟦v⟧} ∈ \vs{{(li : Ai) i∈I}}$ and show that $\t{⟦v⟧} ∈
  \vs{{(li : Bi) i∈I}}$. Again, if $\v{⟦v⟧} = \v{□}$ then the proof is
  trivial. Hence, we may assume $\t{⟦v⟧} = \t{{(li=vi) i∈I}}$ and
  $\v{vi} ∈ {\vs{Ai} ∖ \{\v{□}\}}$ for all index $i∈I$. As a consequence,
  we only need to show that $\v{vi} ∈ \vs{Bi}$ for all $i∈I$. Let us take
  $k∈I$ and consider the term $\t{⟦(λx x.lk) t⟧} = \t{(λx x.lk) ⟦t⟧}$. As
  we have $\t{⟦t⟧} ≡ \t{⟦v⟧} = \t{{(li=vi) i∈I}}$, we know
  $\t{(λx x.lk) ⟦t⟧} ≡ \t{(λx x.lk) {(li=vi) i∈I}}$. We then obtain
  $\t{(λx x.lk) ⟦t⟧} ≡ \t{vk}$ using \theorems(["cbvbeta" ; "equivtrivial"]).
  We can hence conclude using the
  induction hypothesis, the $({≡})$-extensionality of the pole and
  \theorem("main").
  \begin{center}
    $\id(r_prod)$
  \end{center}

\item In the case of the ($×_{ext}$) rule, the proof is similar to the ($×$)
  case. Since we know that $\t{⟦t⟧} ≡ \t{⟦v⟧}$ we can assume $\t{⟦v⟧} ∈
  \vs{{(li : Ai) i∈I₁}}$ and show that $\t{⟦v⟧} ∈ \vs{{(li : Bi) i∈I₂}}$. 
  If $\v{⟦v⟧} = \v{□}$ then the proof is trivial so we may assume that
  $\t{⟦v⟧} = \t{{(li=vi) i∈I}}$ with $I₁ ⊆ I$ and $\v{vi} ∈ \vs{Ai}$ for all
  index $i∈I₁$. As a consequence, we only need to show $\v{vi} ∈ \vs{Bi}$
  for all $i∈I₂$. Let us take $k∈I₂$ and consider the term
  $\t{⟦(λx x.lk) t⟧} = \t{(λx x.lk) ⟦t⟧}$. As
  we have $\t{⟦t⟧} ≡ \t{⟦v⟧} = \t{{(li=vi) i∈I}}$, we know
  $\t{(λx x.lk) ⟦t⟧} ≡ \t{(λx x.lk) {(li=vi) i∈I}}$. Using
  \theorems(["cbvbeta" ; "equivtrivial"]) we obtain
  $\t{(λx x.lk) ⟦t⟧} ≡ \t{vk}$. We can hence conclude using
  the induction hypothesis, the $({≡})$-extensionality of the pole
  and \theorem("main").
  \begin{center}
    $\id(r_prod_ext1)$
  \end{center}

\item In the case of the ($×_{⊂}$) rule, the proof is exactly the same as
  for ($×_{ext}$) with $I = I₁$.
  \begin{center}
    $\id(r_prod_ext2)$
  \end{center}

\item In the case of the ($∀_l$) rule, we need to show that $t ⊩
  \f{∀χ^s A} ⊂ \f{B}$. We thus suppose that $\t{t} ⊩ \f{∀χ^s A}$
  and show $\t{t} ⊩ \f{B}$. By induction hypothesis, it is enough
  to prove $\t{t} ⊩ \f{A[χ≔C]}$ and thus we will show
  $\ts{∀χ^s A} ⊆ \ts{A[χ≔C]}$. According to \lemma("orthoincl"),
  it is enough to show $\vs{∀χ^s A} ⊆ \vs{A[χ≔C]}$, which is
  immediate by definition.
  \begin{center}
    $\id(r_forall_l)$
  \end{center}

\item In the case of the ($∀_r$) rule, we need to show that $t ⊩ \f{A} ⊂
  \f{∀χ^s B}$. We thus suppose that $\t{⟦t⟧} ∈ \ts{A}$ and show that
  $\t{⟦t⟧} ∈ \ts{∀χ^s B}$. We have $\t{⟦t⟧} ∈ \ts{B[χ ≔ εχ∈s(t∉B)]}$
  by induction hypothesis. Moreover, as the pole is $({≡})$-extensional
  and $\t{⟦v⟧} ≡ \t{⟦t⟧}$ for some value $v$, we have $\t{⟦v⟧} ∈
  \ts{B[χ ≔ εχ∈s(t∉B)]}$ according to \theorem("poleext"). For the
  same reason, it will be enough for us to show that
  $\t{⟦v⟧} ∈ \ts{∀χ^s B}$. With \theorem("main") we even have
  $\t{⟦v⟧} ∈ \vs{B[χ ≔ εχ∈s(t∉B)]}$ and we can show
  $\t{⟦v⟧} ∈ \vs{∀χ^s B}$.
  (* *)
  We now suppose that there is $Φ ∈ ⟦s⟧$ such that $\t{⟦t⟧} ∉ \ts{B[χ≔Φ]}$.
  We can thus assume that $\vs{B[χ ≔ εχ∈s(t∉B)]} = \vs{B[χ≔Φ]}$, which
  contradicts $\t{⟦t⟧} ∈ \ts{B[χ≔Φ]}$.
  (* *)
  As a consequence, it must be that for every formula $Φ ∈ ⟦s⟧$ we have
  $\t{⟦t⟧} ∈ \ts{B[χ≔Φ]}$, or equivalently $\t{⟦v⟧} ∈ \vs{B[χ≔Φ]}$ using
  \theorems(["poleext" ; "main"]). This immediately implies that
  $\t{⟦v⟧} ∈ \vs{∀χ^s B}$.
  \begin{center}
    $\id(r_forall_r)$
  \end{center}

\item In the case of the ($∃_r$) rule, the proof is similar as for the
  ($∀_l$) rule. We need to show that $t ⊩ \f{A} ⊂ \f{∃χ^s B}$ so we
  suppose $t ⊩ \f{A}$ and show $t ⊩ \f{∃χ^s B}$. Using the induction
  hypothesis, we know that $\t{t} ⊩ \f{B[χ≔C]}$. As a consequence, we
  only need to show $\ts{B[χ≔C]} ⊆ \ts{∃χ^s B}$. This immediatly follows
  from the definition of $\vs{∃χ^s B}$ using \lemma("orthoincl").
  \begin{center}
    $\id(r_exists_r)$
  \end{center}

\item In the case of the ($∃_l$) rule, the proof is similar as for the
  ($∀_r$) rule. We need to show that $t ⊩ \f{∃χ^s A} ⊂ \f{B}$ so we
  suppose $\t{t} ⊩ \f{∃χ^s A}$ and show $\t{t} ⊩ \f{B}$. To be able to
  use the induction hypothesis, we need to show that $\t{⟦t⟧} ∈
  \ts{A[χ ≔ εχ∈s(t∈A)]}$, provided that $\t{⟦t⟧} ∈ \ts{∃χ^s A}$.
  As we have $\t{⟦v⟧} ≡ \t{⟦t⟧}$ we can use \theorems(["poleext";"main"]),
  assume $\v{⟦v⟧} ∈ \vs{∃χ^s A}$ and show $\v{⟦v⟧} ∈ \vs{A[χ ≔ εχ∈s(t∈A)]}$.
  (* *)
  We will now suppose, by contradiction, that for every element $Φ$ of
  $⟦s⟧$ we have $\t{⟦t⟧} ∉ \ts{A[χ≔Φ]}$ and thus $\t{⟦v⟧} ∉ \vs{A[χ≔Φ]}$
  using again \theorems(["poleext"; "main"]). This is a contradiction
  since this exactly means that $\t{⟦v⟧} ∉ \vs{∃χ^s A}$.
  (* *)
  Hence, there must be $Φ ∈ ⟦s⟧$ such that $\t{⟦t⟧} ∈ \ts{A[χ≔Φ]}$. We
  can thus suppose $\vs{A[χ ≔ εχ∈s(t∈A)]} = \vs{A[χ≔Φ]}$ which gives us
  $\t{⟦t⟧} ∈ \ts{A[χ ≔ εχ∈s(t∈A)]}$. We can thus conclude
  the proof using \theorems(["poleext"; "main"]) one more time.
  \begin{center}
    $\id(r_exists_l)$
  \end{center}

\item In the case of the ($\restriction_l$) rule, we need to show that $t ⊩
  \f{A∧u₁≡u₂} ⊂ B$. We thus assume that we have $\t{⟦t⟧} ∈ \ts{A∧u₁≡u₂}$ and
  we show $\t{⟦t⟧} ∈ \ts{B}$. As in the case of the ($⇒$) rule, we know that
  $\t{⟦t⟧} ≡ \t{⟦v⟧}$ so we can assume that we have $\t{⟦v⟧} ∈ \vs{A∧u₁≡u₂}$
  and we can show $\t{⟦v⟧} ∈ \vs{B}$. Now, if $\v{⟦v⟧} = \v{□}$ then we can
  conclude immediately. Otherwise, we have $\v{⟦v⟧} ∈ \vs{A}$ and
  $\t{⟦u₁⟧} ≡ \t{⟦u₂⟧}$ by definition of $\vs{A∧u₁≡u₂}$. As a consequence,
  we get $\t{⟦v⟧} ∈ \vs{B}$ by induction hypothesis (using $\t{⟦u₁⟧} ≡
  \t{⟦u₂⟧}$).
  \begin{center}
    $\id(r_rest_l)$
  \end{center}

\item In the case of the ($\restriction_r$) rule, we need to show that
  $t ⊩ A ⊂ \f{B∧u₁≡u₂}$. We thus assume $\t{t} ⊩ \f{A}$ and show $\t{t}
  ⊩ \f{B∧u₁≡u₂}$. Using the induction hypothesis, we know that $\t{t} ⊩
  \f{B}$. We will thus conclude the proof by showing $\vs{B∧u₁≡u₂}
  = \vs{B}$, which implies $\ts{B∧u₁≡u₂} = \ts{B}$. This is immediate
  since $\t{⟦u₁⟧} ≡ \t{⟦u₂⟧}$ by hypothesis.
  \begin{center}
    $\id(r_rest_r)$
  \end{center}

\item In the case of the ($∈_l$) rule, we need to show that $t ⊩ \f{u∈A}
  ⊂ B$. We thus assume that we have $\t{t} ⊩ \f{u∈A}$ and show $\t{t} ⊩
  \f{B}$. As in the case of the ($⇒$) rule, we know that $\t{⟦t⟧}≡\t{⟦v⟧}$
  so we can assume that we have $\v{⟦v⟧} ∈ \vs{u∈A}$ and show $\t{⟦v⟧} ∈
  \ts{B}$. As $\t{⟦v⟧} ∈ \vs{u∈A}$, we have $\t{⟦v⟧} ≡ \t{⟦u⟧}$ and
  $\t{⟦v⟧} ∈ \vs{A}$ by definition. We can thus conclude by using the
  induction hypothesis to get $\t{⟦v⟧} ∈ \vs{B}$ since we know
  $\t{⟦t⟧} ≡ \t{⟦u⟧}$.
  \begin{center}
    $\id(r_memb_l)$
  \end{center}

\item In the case of the ($∈_r$) rule, we need to show that $t ⊩ A ⊂
  \f{u∈B}$. We thus suppose that $\t{t} ⊩ \f{A}$ and show $\t{t} ⊩
  \f{u∈B}$. Using the first induction hypothesis, we know that
  $\t{t} ⊩ \f{B}$. Now, as the pole is $({≡})$-extensional and
  $\t{⟦v⟧} ≡ \t{⟦t⟧}$ for some value $v$, we can use \lemma("poleext")
  and \theorem("main") to obtain $\t{⟦v⟧} ∈ \vs{B}$. For a similar
  reason, it is enough to show that $\t{⟦v⟧} ∈ \ts{u∈B}$. By
  definition of $\vs{u∈B}$, it only remains to show $\t{⟦v⟧} ≡ \t{⟦u⟧}$,
  which follows by transitivity of $({≡})$ knowing $\t{⟦v⟧} ≡ \t{⟦t⟧}$
  and $\t{⟦t⟧} ≡ \t{⟦u⟧}$.
  \begin{center}
    $\id(r_memb_r)$
  \end{center}
  \linesAfter(0) (* FIXME hack *)
\end{itemize}
\end{proof}
\end{thm}

=<

=> Completeness on pure data types

In the previous section, the semantics was shown to be adequate with
respect to our typing rules. In other words, typed programs really are
what they are expected to be in the semantics. Our adequacy lemma
(\theorem("fulladequacy")) is thus a soundness result, and we are now
going to wonder about completeness.

Although we cannot hope for a full completeness of our semantics, it is
still possible to show that our system is complete when restricted to
simple enough types. In particular, we will consider types that do not
contain arrow (or function) types. They will not contain quantifiers
either.
\begin{def}
A type $A ∈ \cal{F}$ is said to be a //pure data type// if it is only
constructed using sum types and strict product types. In other words,
a pure data type is generated by the following ||bnf|| grammar. We will
denote $\cal{F}₀$ the set of all the pure data types.
\begin{center}
\Caml(
let _ =
  bnfs
  [ ( << $(\cal{F}₀)$ >>
    , << $A, B$ >>
    , << $\f{{(li : Ai) i∈I}} \| \f{[(Ci : Ai) i∈I]} $ >>
    , [] ) ]
)
\end{center}
\end{def}
Here, pure data types are rather limited. However, if the system was
extended with inductive types, then they could also be included in the
definition. As a consequence, pure data types would contain, for
example, unary natural numbers or lists.

\begin{thm}
Let $\f{A} ∈ \cal{F}₀$ be a pure data type. For every value $\v{v} ∈
{\vs{A} ∖ \{\v{□}\}}$ the judgment $⊢ v : A$ is derivable.
\begin{proof}
We do a proof by induction on the structure of $\f{A}$. If it is of the
form $\f{{(li : Ai) i∈I}}$ then by definition $\v{v} = \v{{(li = vi)i∈I}}$
with $\v{vi} ∈ {\vs{Ai} ∖ \{\v{□}\}}$ since $v ≠ \v{□}$. As a consequence,
the induction hypotheses give us a proof of $⊢ \v{vk} : \f{Ak}$ for all
$k ∈ I$. We can thus build a proof of
$⊢ \v{{(li = vi)i∈I}} : \f{{(li : Ai) i∈I}}$ as follows.
\begin{proofTree}
\Caml(
let p =
  ax       ~name:<$Ax_{⊂}$>
    <$⊢ \v{{(li = vi)i∈I}} ∈ \f{{(li : Ai) i∈I}} ⊂ \f{{(li : Ai) i∈I}}$>;
  hyp <$[⊢ \v{vi} : \v{Ai}]_{i∈I}$>;
  binary   ~name:<$×_i$> <$⊢ \v{{(li = vi)i∈I}} : \f{{(li : Ai) i∈I}}$>;
  display_proof ()
)
\begin{center}
$$\fit(p)$$
\end{center}
\end{proofTree}
Note that the base case of our induction is the empty record type $\f{{}}$.
In this case the above proof does not have any open premise.

If $A$ is of the form $\f{[(Ci : Ai) i∈I]}$ then by definition we have
$\v{v} = \v{Ck[w]}$ with $k ∈ I$ and $\v{w} ∈ {\vs{Ak} ∖ \{\v{□}\}}$ since
$v ≠ \v{□}$. Our induction hypothesis hence gives us a derivation of
$⊢ \v{w} : \f{Ak}$ that we can use to build a proof of
$⊢ \v{Ck[w]} : \f{[(Ci : Ai) i∈I]}$ as follows.
\begin{proofTree}
\Caml(
let p =
  hyp     <$⊢ \v{w} : \v{Ak}$>;
  hyp     <$\{k\} ⊆ I$>;
  ax      ~name:<$Ax_{⊂}$> <$⊢ \t{(λx[x|Ck[xk]→xk]) Ck[w]} ∈ \f{Ak} ⊂ \f{Ak}$>;
  hyp     <$⊢ \v{Ck[w]} ≡ \v{Ck[w]}$>;
  ternary ~name:<$+$>
          <$⊢ \v{Ck[w]} ∈ \f{[Ck : Ak]} ⊂ \f{[(Ci : Ai) i∈I]}$>;
  binary  ~name:<$+_i$> <$⊢ \v{Ck[w]} : \f{[(Ci : Ai) i∈I]}$>;
  display_proof ()
)
\begin{center}
$$\fit(p)$$
\end{center}
\end{proofTree}
\end{proof}
\end{thm}

=<

=> Normalisation, safety and consistency

Thanks to our new adequacy lemma (\theorem("fulladequacy")), we can now
study the properties of our system. Although a normalisation result was
already given in \chapter("typeSystem"), we cannot reuse it since our
type system and its semantics have been modified. We will however use
very similar techniques, which consist in considering particular examples
of poles.

In this thesis, the choice of a pole is more constrained than it usually
is the framework of classical realizability (e.g., \mcite(["Krivine2009";
"Miquel2011"])). Indeed, the only property that is commonly required of
a pole is to be saturated under the reduction relation of the abstract
machine (i.e., to be closed under backward reduction). Here however, we
need to ask for more properties. Our poles need to be $({≡})$-extensional
for the semantics of our types to be closed under equivalence. Moreover,
they must satisfy the conditions of our main theorem (\theorem("main")).
In particular they must only contain terminating processes and they must
include the process $\p{□∗ε}$.

\begin{thm}\label("fullnorm")
Every closed, typed term normalises. More precisely, for every term
$t∈Λ^{∗}$ such that $⊢ t : A$ is derivable, there is $v∈{Λ_ι^{∗} ∖
\{\v{□}\}}$ such that $\p{t∗π} ↠^{∗} \p{v∗ε}$.
\begin{proof}
We consider the pole $\dbot=\{p ∈ Λ∗Π \| ∃v∈Λ_ι, p ↠^{∗} \p{v∗ε}\}$ which is
trivially saturated. Moreover, this pole only contains processes that reduce
to a final state. Let us now verify that $\dbot$ is $≡$-extensional. We thus
suppose that $t ≡ u$ and that $\p{t∗π} ∈ \dbot$. By definition of $\dbot$,
there must be a value $v$ such that $\p{t∗π} ↠^{∗} \p{v∗ε}$. This means that
there must be $k ∈ \bbN$ such that $\p{t∗π} ↠_k^{∗} \p{v∗ε}$, and hence we
have ${\p{t∗π}} {⇓}_{↠}$. Since $t ≡ u$ we can deduce ${\p{u∗π}} {⇓}_{↠}$,
and thus there must be a value $w$ such that $\p{u∗π} ↠_k^{∗} \p{w∗ε}$. As
a consequence, we have $\p{u∗π} ↠^{∗} \p{w∗ε}$, which gives us
$\p{u∗π} ∈ \dbot$.

We can now apply \theorem("fulladequacy") with the pole $\dbot$ and obtain
$\t{t} ⊩ \f{A}$. Since $t ∈ Λ^{∗}$, it cannot contain any choice operator
and we have $\t{⟦t⟧} = \t{t} ∈ \ts{A}$ by definition. This means that
$\p{t∗π} ∈ \dbot$ for every stack $π ∈ \ss{A}$. In particular, we have
$\p{t ∗ ε} ∈ \dbot$ as we trivially have $ε ∈ \ss{A}$. This exactly means
that there is a value $v∈Λ_ι$ such that $\p{t∗ε} ↠^{∗} \p{v∗ε}$. It remains
to show that $v$ is closed and different from $\v{□}$. This follows from
the fact that $\p{t∗ε}$ is closed and that it does not contain $\v{□}$
since none of our reduction rules can introduce free variables or the
value $\v{□}$.
\end{proof}
\end{thm}

Now that we have proved normalisation, we will show that our system is
type safe. In other words, a typed program is expected to reduce to a value
of the corresponding type. For instance, a program which type corresponds
to some encoding of the natural numbers is expected to evaluate to a
value representing a natural number. As usual in classical realizability,
we do not prove type safety for all types. In particular, safety is never
proved for types containing function arrows. We will here restrict ourselves
to pure data types.
\begin{rem}
The restriction to pure data types is not a problem in practice. For
example, functions can only be observed through their application. In
particular, placing a function in a well-typed context will only allow
us to observe well-typed output. Similar arguments apply to all the type
constructors that are not directly considered for type safety.
\end{rem}

Even when we restrict to pure data types, the proof of type safety is
subtle in our system. The difficult part consist in showing that the pole
defined from the value level interpretation of a pure data type is
$≡$-extensional. This is in fact possible thanks (again) to our
$\t{δ(v,w)}$ term constructor.
\begin{thm}\label("fullsafety")
For every closed term $t ∈ Λ_ι^{∗}$ such that $⊢ t : A$ for a pure
data type $A ∈ \cal{F}₀$, there is a value $v ∈ {\vs{A} ∖ \{\v{□}\}}$
such that $\p{t∗ε} ↠^{∗} \p{v∗ε}$.
\begin{proof}
We consider the pole $\dbot_A = \{p ∈ Λ∗Π \| ∃v∈\vs{A}, p ↠^{∗} \p{v∗ε}\}$
which is trivially saturated. Moreover, this pole only contains processes
that reduce to a final state. Note that the set $\vs{A}$ can be used in the
definition of $\dbot_A$ because $A$ is a pure data type. In particular,
the type $A$ does not contain arrow types. If they did, the definition would
be circular as the pole is used in the interpretation of the arrow type.
(* *)
Let us now verify that $\dbot_A$ is $≡$-extensional. We thus
suppose that $t ≡ u$ and that $\p{t∗π} ∈ \dbot_A$. By definition there must
be a value $v∈\vs{A}$ such that $\p{t∗π} ↠^{∗} \p{v∗ε}$. Now, since $t ≡ u$
there must be $w∈Λ_ι$ such that $\p{u∗π} ↠^{∗} \p{w∗ε}$ and it remains to
show that $w ∈ \vs{A}$. To conclude, it is enough to show $w ≡ v$ as we know
that $\vs{A}$ is closed under $({≡})$.
(* *)
Let us now apply the substitution $\subs{ρ} = \subs{[ε ≔ [λx δ(v,x)]ε]}$ to
$\p{t∗π}$. We thus obtain $\p{(t∗π)ρ} ↠^{∗} \p{vρ∗[λx δ(v,x)]ε}$ and since
$A$ is a pure data types, it is easy to see that $\v{v}$ cannot contain
terms (since they only appear in $λ$-abstractions) nor stacks (since they
only appear in terms). As a consequence, we have $\p{(t∗π)ρ} ↠^{∗}
\p{v∗[λx δ(v,x)]ε} ↠^{2} \p{δ(v,v)∗ε}$, which is stuck. As a consequence,
we know that $\p{tρ ∗ πρ} ∉ \dbot$.
(* *)
Now, since we have $t ≡ u$, we can apply \theorem("poleext") and obtain
that $\p{uρ ∗ πρ} ∉ \dbot$. By applying reduction steps, we obtain that
$\p{wρ ∗ [λx δ(v,x)]ε}$ is not in $\dbot$ either. Now, since we have
$\p{wρ ∗ [λx δ(v,x)]ε} ↠^{2} \p{δ(v,wρ)∗ε}$ then we also know that
$\p{δ(v,wρ)∗ε} ∉ \dbot$. This can only be true if $\v{wρ} ≡ \v{v}$.
Now, since $\vs{A}$ is closed under $({≡})$ then it must be that
$\v{wρ} ∈ \vs{A}$. As mentioned above, the elements of $\vs{A}$ cannot
contain the empty stack symbol $\s{ε}$ and thus we have $\v{wρ} = \v{w}$,
which gives $\v{w} ∈ \vs{A}$.

We can now apply \theorem("fulladequacy") with the pole $\dbot_A$ and obtain
$\t{t} ⊩ \f{A}$. Since $t ∈ Λ^{∗}$ it cannot contain any choice operator,
and thus we have $\t{⟦t⟧} = \t{t} ∈ \ts{A}$ by definition. This means that
$\p{t∗π} ∈ \dbot_A$ for every stack $ξ ∈ \ss{A}$. In particular, we have
$\p{t ∗ ε} ∈ \dbot_A$ as we trivially have $ε ∈ \ss{A}$. This exactly means
that there is a value $v∈\vs{A}$ such that $\p{t∗ε} ↠^{∗} \p{v∗ε}$. Moreover,
$\v{v} ≠ \v{□}$ since a typed term cannot contain $\v{□}$.
\end{proof}
\end{thm}

One of the applications of our type safety theorem is to show the consistency
of the system. In particular, we can immediately show that the type $\f{[]}$
(i.e., the empty sum type) is empty. In other words, there should be no
typable program of type $\f{[]}$.
\begin{thm}\label("fullconsistency")
There is no closed term $t ∈ Λ^{∗}$ such that $⊢ t : \f{[]}$ is derivable.
\begin{proof}
Let us assume that there a term $t ∈ Λ^{∗}$ that $⊢ t : \f{[]}$. As $\f{[]}$
is a pure data type we can apply \theorem("fullsafety") to obtain a value
$v ∈ \vs{[]}$ such that $\p{t∗ε} ↠^{∗} \p{v∗ε}$. However, we have $\vs{[]} =
\{\v{□}\}$ so it must be that $\v{v} = \v{□}$. This is a contradiction since
we know that the process $\p{t∗ε}$ does not contain $\v{□}$, and thus
$\p{v∗ε}$ cannot contain $\v{□}$ either according to \lemma("noboxred").
\end{proof}
\end{thm}

In our system, there are many ways of building an empty type. As a
consequence, \theorem("fullconsistency") is not enough for ensuring
the consistency of the system as it only considers the type $\f{[]}$.
However, the other forms of empty type can be handled using typing.
Let us consider the type $\f{∀X X}$, which also denotes an empty type.
Let us suppose that we have a term $t$ such that $⊢ t : \f{∀X X}$ and
$t$ does not contain $\v{□}$. We can then build the following typing
derivation, which gives a term of type $\f{[]}$.
\begin{proofTree}
\Caml(
let p =
  ax       ~name:<$Ax_{⊂}$> <$⊢ \v{λx x} ∈ \f{(∀X X)⇒[]} ⊂ \f{(∀X X)⇒[]} $>;
  ax       ~name:<$Ax_{⊂}$> <$⊢ \v{εx∈∀X X(x ∉ [])} ∈ \f{[]} ⊂ \f{[]}$>;
  unary    ~name:<$∀_l$> <$⊢ \v{εx∈∀X X(x ∉ [])} ∈ \f{∀X X} ⊂ \f{[]}$>;
  unary    ~name:<$Ax$>  <$⊢ \v{εx∈∀X X(x ∉ [])} : \f{[]}$>;
  binary   ~name:<$⇒_i$> <$⊢ \v{λx x} : \f{(∀X X)⇒[]}$>;
  hyp      <$⊢ \t{t} : \f{∀X X}$>;
  binary   ~name:<$⇒_e$> <$⊢ \t{(λx x) t} : \f{[]}$>;
  display_proof ()
)
\begin{center}
$$\fit(p)$$
\end{center}
\end{proofTree}
The existence of such a term contradicts \theorem("fullconsistency")
and thus there cannot exist terms such as $t$. Similar proofs can be
made for other forms of empty types.

=<

=> Toward (co-)inductive types and recursion

The type system described in this chapter does not yet contain all the
ingredients required for a practical programming language and proof
system. Indeed, it lacks inductive types and does not allow recursion.
In this section, we will hint toward the inclusion of these features. To
this aim, we will rely on the approach described in \cite("Lepigre2017")
by Christophe Raffalli and the author. In particular, we will extend the
system with typing rules allowing the construction of infinite typing
and subtyping derivations. We will then rely on a notion of //syntactic
ordinals// to show that they are well-founded and thus correct.

In the system, ordinals will be handled using another atomic sort, which
will automatically provide us with quantification over ordinals. In our
types, ordinals will be used to annotate inductive (and coinductive)
types with a size information. As a consequence, they will allow us to
extend our system with sized types \mcite(["Hughes1996"; "Abel2008";
"Lepigre2017"]). In the semantics, syntactic ordinals will be interpreted
using actual ordinals.
\begin{def}
We denote $κ$ the sort of //syntactic ordinals//. From now on, we will
consider that it is contained in our set of atomic sorts $\cal{S}₀$
and thus $κ ∈ \cal{S}$.
\end{def}
\begin{def}
The set of all the syntactic ordinals is generated from a set of ordinal
variables $\cal{V}_κ = \{θ, η, ζ ...\}$ using the following ||bnf|| grammar.
\begin{center}
\Caml(
let _ =
  bnfs
  [ ( << $(\cal{O})$ >>
    , << $τ, υ$ >>
    , << $\o{θ} \| \o{∞} \| \o{τ+1} \| \o{εθ<τ(t∈A)} $ >>
    , << $θ ∈ \cal{V}_κ, t ∈ Λ^{+}, A ∈ \cal{F}$ >> ) ]
)
\end{center}
Our syntactic ordinals are formed using variable, the constant $\o{∞}$, the
successor symbol and choice operators of the form $\o{εθ<τ(t∈A)}$. Note that
we need to extend the system with the following three sorting rules.
$$
  \axiomR{Σ ⊢ \o{∞} : κ}
  \hspace(3.0)
  \unaryR{Σ ⊢ \o{τ} : κ}{Σ ⊢ \o{τ+1} : κ}
  \hspace(3.0)
  \ternaryR{Σ ⊢ τ:κ}{Σ, θ:κ ⊢ t:τ}{Σ, θ:κ ⊢ A : ο}{Σ ⊢ \o{εθ<τ(t∈A)}:κ}
$$
\end{def}
(*
Note that we do not need to include a sorting rule for ordinal variables as
they are handled like other kinds of variables.
*)

In the model, syntactic ordinals will be interpreted using actual ordinals,
as is done in \cite("Lepigre2017"). In particular, $∞$ will be interpreted
by an ordinal that is large enough to ensure the convergence of all
fixpoints in the semantics of our types.
\begin{def}
Given a syntactic ordinal $τ$, we denote $⟦\o{τ}⟧$ the ordinal corresponding
to its interpretation. In particular, we define $⟦\o{∞}⟧$ to be the set of
all the ordinals smaller or equal to the cardinal of the set $\cal{P}(⟦ο⟧)$.
The interpretation of the other syntactic ordinals is defined inductively as
follows.
\begin{center}
\diagram(
let contents =
  let line s1 s2 = [s1 ; <$ = $> ; s2] in
  two_cols
  [ line <$⟦o⟧$>       <$o$>
  ; line <$⟦\o{τ+1}⟧$> <$⟦\o{τ}⟧+1$>
  ; line <$⟦\o{εθ<τ(t∈A)}⟧$> <$o \st \t{⟦t[θ≔o]⟧} ∈ \ts{A[θ≔o]}$>
  ; line <$⟦\o{εθ<τ(t∈A)}⟧$> <$0 \hspace(0.4) otherwise$> ]
let _ = array [`East; `Main; `West; `East; `Main; `West] contents
          ~horizontal_padding:(fun n -> if n = 3 then 10.0 else 1.0)
          ~vertical_padding:(fun n -> 2.0)
)
\end{center}
We will use the notation $⟦\cal{O}⟧$ for the ordinal $⟦\o{∞}⟧+ω$, which
is the set of all the ordinals that can be represented in our syntax.
\end{def}
\begin{rem}
As in the previous chapter, the multiple extensions of the language that
are given in this chapter are not independent. As our syntactic elements
are all defined mutually inductively, every single modification leads to
global changes. In particular, the definition of types (and thus of raw
terms) is affected.
\end{rem}

We will now extend the syntax of our types with two constructors denoting
the least or greatest fixpoint of a parametric type. Intuitively, these
types will allow us to construct inductive and coinductive types. As we
are using sized types, our fixpoint constructors will have the peculiarity
of carrying an ordinal. In particular, a fixpoint carrying the ordinal
$\o{∞}$ will correspond to usual (not sized) types.
\begin{def}
We extend the syntax of formulas $\cal{F}$ with a least fixpoint constructor
$\f{μτX A}$ and a greatest fixpoint constructor $\f{ντX A}$. Both of these
constructors carry an ordinal. Note that we need to extend our system with
the following sorting rules.
\begin{center}
$\binaryR{Σ, X:ο ⊢ A : ο}{Σ ⊢ τ : κ}{Σ ⊢ \f{μτX A} : ο}$
\hspace(6.0)
$\binaryR{Σ, X:ο ⊢ A : ο}{Σ ⊢ τ : κ}{Σ ⊢ \f{ντX A} : ο}$
\end{center}
Moreover, we will implicitly assume that in these constructions, the variable
$X$ only appears positively in $A$ (i.e., it is in covariant position).
\end{def}
\begin{def}
In the semantics, sized inductive and coinductive types are interpreted in
the usual way, as pre-fixpoints and post-fixpoints respectively.
$$
  \vs{μτX A} = \bigcup_{o < ⟦\o{τ}⟧} ⟦X ↦ A⟧^o(\{\v{□}\})
  \hspace(6.0)
  \vs{ντX A} = \bigcap_{o < ⟦\o{τ}⟧} ⟦X ↦ A⟧^o(Λ_ι)
$$
\end{def}

Before giving the new subtyping rule for handling inductive and coinductive
type, we need to extend the context of our judgments with a so-called
positivity context.
\begin{def}
A //positivity context// is a list of syntactic ordinals assumed to be
positive. For convenience, we will represent such contexts using
comma-separated lists of syntactic ordinals generated by the following
||bnf|| grammar.
\Caml(let _ = sidenote << $γ ::= ∅ \| {γ, τ} $ >> << $τ ∈ \cal{O} $ >>)
We will say that a positivity context $γ$ is valid if the interpretation of
every syntactic ordinal $τ$ of $γ$ is strictly positive (i.e., $⟦τ⟧ > 0$).
\end{def}
In the system, positivity contexts will be necessary for the derivation of
ordering judgments on syntactic ordinals. They will be used to make sure
that fixpoints can be unfolded in subtyping judgments.
\begin{def}
An //ordering judgment// is a tuple of a positivity context $γ$, syntactic
ordinals $τ$ and $υ$ and an integer $i ∈ \bbZ$ denoted $γ ⊢ τ ≤_i υ$. An
ordering judgment is said to be valid if it can be derived using the
deduction rules given in \figRef("orderingrules"). Note that we will write
$γ ⊢ τ < υ$ when $i = 1$.
\end{def}
\Caml(let _ = ordering_rules ()) (* NOTE can be moved *)
\Caml(let _ = extra_subrules ()) (* NOTE can be moved *)
\begin{def}
We extend our system with the six subtyping rules given in 
\figRef("extrasubrules"). Note that all the other rules need to be
modified to contain a positivity context. However, there is no
difficulty in doing so as they only need to transmit this context.
\end{def}

Intuitively, the ($μ_{r,∞}$) rules allows the unrolling of a least fixpoint
on the right side of the subtyping relation. This rule can only be applied
when the limit of the fixpoint has been reached, and it is always the case
with the ordinal $∞$. When the ordinal is too small to make the fixpoint
converge, the ($μ_r$) rule can be applied. However, it requires finding an
ordinal $υ$ that is strictly smaller than the ordinal $τ$ carried by the
fixpoint. In particular, this ensures that $τ$ was not equal to $0$, and
thus that the fixpoint can be unrolled. When a least fixpoint appears on
the left side of a pointed subtyping relation, the ($μ_l$) rule can be
applied. In this case, a choice operator is used to obtain some ordinal
such that the left part of the judgment is satisfied. If no such ordinal
exist, then $0$ is chosen and thus the premise of the rule is immediate.
The three rules for handling the greatest fixpoint constructor are dual
to those for the least fixpoint constructor.

Handling recursion requires providing a typing rule for our fixpoint
term constructor. However, this is not enough because in practice we will
need (part of) our positivity contexts to be communicated between part of
the typing trees to be able to establish that an infinite typing proof is
well-founded. As a consequence, we also introduce two new type connectives
that will be used for this purpose. In particular, they will allow us to
give stronger rules for the typing of $λ$-abstractions and pattern matchings.
\begin{def}
We extend the syntax of formulas $\cal{F}$ with two new type constructors
$\f{A ∧ γ}$ and $\f{γ ↪ A}$ called positivity restriction and positivity
implication. The former is a variant of our restriction constructor for
equivalences and the latter denotes an implication (with no algorithmic
contents) depending on a positivity context. Note that we need to extend
the system with the following sorting rules.
\begin{center}
$\binaryR{Σ ⊢ A : ο}{(Σ ⊢ τ : κ)_{τ∈γ}}{Σ ⊢ \f{A ∧ γ} : ο}$
\hspace(6.0)
$\binaryR{Σ ⊢ A : ο}{(Σ ⊢ τ : κ)_{τ∈γ}}{Σ ⊢ \f{γ ↪ A} : ο}$
\end{center}
\end{def}
\begin{def}
In the semantics, positivity restriction and positivity implication are
interpreted as follows.
\begin{center}
\diagram(
let contents =
  let line s1 s2 = [ <$\vs(s1)$> ; <$ = $> ; <$\mathsText(s2)$>] in
  two_cols
  [ line "A ∧ γ" <<$\vs{A}$ when $∀τ∈γ, ⟦τ⟧ > 0$>>
  ; line "γ ↪ A" <<$\vs{A}$ when $∀τ∈γ, ⟦τ⟧ > 0$>>
  ; line "A ∧ γ" <<$\{\v{□}\}$ otherwise>>
  ; line "γ ↪ A" <<$Λ_ι$ otherwise>> ]
let _ = array [`East; `Main; `West; `East; `Main; `West] contents
          ~horizontal_padding:(fun n -> if n = 3 then 10.0 else 1.0)
          ~vertical_padding:(fun n -> 2.0)
)
\end{center}
\end{def}
\begin{rem}
It would be perfectly possible to add an implication connective similar
to $\f{γ ↪ A}$ but depending on an equivalence instead of a list of
ordinals. It is in fact included in the implementation of the system.
\end{rem}

We will now extend our system with a last set of rules typing and local
subtyping rules for handling recursion. We will then prove that all the
rules introduced in this section are adequate.
\begin{def}
We extend the system with the seven rules of \figRef("extraordsubrules").
\end{def}
We can now put everything together and prove yet another adequacy lemma.
However, we first need to give the interpretation of ordinal ordering
judgments.
\begin{lem}\label("ordord")
If the judgment $γ ⊢ τ₁ ≤_i τ₂$ is derivable and if for every syntactic
ordinal $τ ∈ γ$ we have $⟦τ⟧ > 0$ then we have the following.
\begin{itemize}
\item If $i ≥ 0$ then $⟦τ₁⟧ + i ≤ ⟦τ₂⟧$,
\item if $i ≤ 0$ then $⟦τ₁⟧ ≤ ⟦τ₂⟧ + i$.
\end{itemize}
\Caml(let _ = extra_ord_subrules ()) (* NOTE can be moved *)
Here, we use the notation $o+i$ for the $i$-th successor of the ordinal
$o$. Note that in particular, $γ ⊢ τ₁ < τ₂$ is derivable then we have
$⟦τ₁⟧ < ⟦τ₂⟧$.
\begin{proof}
A complete proof is given in \id(citen "Lepigre2017" "Lemma 1.10").
\end{proof}
\end{lem}
\begin{thm}\label("uselessadequacy")
Let $γ$ be a positivity context, $Ξ$ be an equational context, $A$,
$B ∈ \cal{F}$ be closed types and $t ∈ Λ^{+}$ be a closed raw term.
If for every syntactic ordinal $τ ∈ γ$ we have $⟦τ⟧ > 0$ and if for
every $(\t{t₁},\t{t₂}) ∈ Ξ$ the equivalence $\t{⟦t₁⟧} ≡ \t{⟦t₂⟧}$
holds then we have the following.
\begin{itemize}
\item If $γ; Ξ ⊢ t : A$ is valid then we have $t ⊩ A$. Moreover, if $t$
      is a value $\t{⟦t⟧} ≠ \v{□}$.
\item If $γ; Ξ ⊢ π : ¬A$ is valid then we have $π ⊩ A$.
\item If $γ; Ξ ⊢ t ∈ A ⊂ B$ is valid then we have $t ⊩ A ⊂ B$.
\end{itemize}
\begin{proof}
The proof proceeds as for \theorem("fulladequacy") with the exception
of the management of the positivity context. For all the rules that
were given in previous sections of the current chapter, the adaptation
is immediate as the positivity context is only transmitted. As a
consequence, we only consider the rules that were introduced in this
section.
\begin{itemize}
\item In the case of the ($μ_{r,∞}$) rule, we need to show that
  $t ⊩ \f{A} ⊂ \f{μ∞ X B}$. By induction hypothesis, we know that
  $t ⊩ \f{A} ⊂ \f{B[X ≔ μ∞ X B]}$ so we can conclude immediately
  as we know that $\vs{μ∞ X B} = \vs{B[X ≔ μ∞ X B]}$ as the
  fixpoint has been reached.
  \begin{center}
    $\id(r_mu_r_inf)$
  \end{center}

\item In the case of the ($ν_{r,∞}$) rule, the proof is dual to the
  ($μ_{r,∞}$) case.
  \begin{center}
    $\id(r_nu_l_inf)$
  \end{center}

\item In the case of the ($μ_r$) rule, we need to show that
  $t ⊩ \f{A} ⊂ \f{μτ X B}$. According to \lemma("ordord") we
  have $⟦υ⟧ < ⟦τ⟧$ and thus we have
  $\vs{B[X ≔ μυ X B]} = \vs{μυ+1 X B} ⊆ \vs{μτ X B}$. We can
  thus conclude using \lemma("orthoincl") and the induction
  hypothesis. It is important that $X$ only appears positively
  in $B$ to obtain the inclusion directly.
  \begin{center}
    $\id(r_mu_r)$
  \end{center}

\item In the case of the ($ν_l$) rule, the proof is dual to the
  ($μ_r$) case.
  \begin{center}
    $\id(r_nu_l)$
  \end{center}

\item In the case of the ($μ_l$) rule, we need to show that $t ⊩ \f{μτ X A}
  ⊂ \f{B}$. If we have $⟦τ⟧ = 0$ then we can conclude immediately as in this
  case $\vs{μτ X A} = \{\v{□}\} ⊆ \vs{B}$ and thus $\ts{μτ X A} ⊆ \ts{B}$ by
  \lemma("orthoincl"). We can thus suppose that $⟦τ⟧ > 0$ in the following
  so that we can use the induction hypothesis. Let now suppose that we have
  $\t{⟦t⟧} ∈ \ts{μτ X A}$ and show $\t{⟦t⟧} ∈ \ts{B}$. By our second
  hypothesis, we have a value $v$ such that $\t{⟦t⟧} ≡ \v{⟦v⟧}$. As a
  consequence we can work at the value level thanks to \theorem("main"). We
  can thus suppose that $\t{⟦v⟧} ∈ \vs{μτ X A}$ and show $\t{⟦v⟧} ∈ \vs{B}$.
  By definition of $\vs{μτ X A}$ we know that there is an ordinal $o < ⟦τ⟧$
  such that $v ∈ ⟦X ↦ A⟧^o(\{\v{□}\})$. As a consequence, the choice operator
  $\o{εθ<τ(v∈A[X ≔ μθX A])} = \o{εθ<τ(t∈A[X ≔ μθX A])}$ is well-defined and
  thus we have $\t{⟦v⟧} ∈ \vs{A[X ≔ μεθ<τ(t∈A[X ≔ μθX A])X A]}$. We can
  hence apply the induction hypothesis (again using \theorem("main")) to get
  $\t{⟦v⟧} ∈ \vs{B}$.
  \begin{center}
    $\id(r_mu_l)$
  \end{center}

\item In the case of the ($ν_r$) rule, the proof is dual to the
  ($μ_l$) case.
  \begin{center}
    $\id(r_nu_r)$
  \end{center}

\item In the case of the ($\restriction_{l,κ}$) rule, the proof is
  similar as for ($\restriction_l$) \theorem("fulladequacy").
  \begin{center}
    $\id(r_ordrest_l)$
  \end{center}

\item In the case of the ($\restriction_{r,κ}$) rule, the proof is
  similar as for ($\restriction_r$) in \theorem("fulladequacy").
  \begin{center}
    $\id(r_ordrest_r)$
  \end{center}

\item In the case of the ($↪_{l,κ}$) rule, we need to show $t ⊩ \f{γ₀ ↪ A}
  ⊂ \f{B}$. Thanks to our second premise we know that all the ordinals in
  $γ₀$ are positive. As a consequence we know that $\vs{γ₀ ↪ A} = \vs{A}$.
  We can thus conclude using \theorem("orthoincl") and the induction
  hypothesis.
  \begin{center}
    $\id(r_ordimpl_l)$
  \end{center}

\item In the case of the ($↪_{r,κ}$) rule, we need to show
  $t ⊩ A ⊂ \f{γ₀↪B}$. We thus suppose that $\t{⟦t⟧} ∈ \ts{A}$ and
  show $\t{⟦t⟧} ∈ \ts{γ₀↪B}$. If the ordinals of $γ₀$ are not all
  positive then the proof is immediate as $\vs{γ₀ ↪ B} = Λ_ι^{∗}$.
  If all the ordinals are positive then we can immediately conclude
  using the induction hypothesis.
  \begin{center}
    $\id(r_ordimpl_r)$
  \end{center}

\item In the case of the ($⇒_{i,κ}$) rule, we need to show $\t{λx t} ⊩ C$.
  Using the first induction hypothesis it is enough to show $\t{λx t} ⊩
  \f{γ₀↪(A⇒B)}$. Let us first assume that some ordinal of $γ₀$ is equal
  to $0$. In this case $\vs{γ₀↪(A⇒B)} = Λ_ι^{∗}$ and thus we have
  $\v{λx ⟦t⟧} ∈ \vs{γ₀↪(A⇒B)}$ so we can conclude with \lemma("orthosimple").
  Now, if $γ₀$ only contains positive ordinals then we have $\vs{γ₀↪(A⇒B)}
  = \vs{A⇒B}$ and we can use the second induction to conclude the proof as
  in the ($⇒_i$) case.
  \begin{center}
    $\id(r_arrow_ord_i)$
  \end{center}

\item In the case of the ($+_{e,κ}$) rule, we need to show
  $\t{[v | (Ci[xi] → ti) i∈I]} ⊩ C$. By our first induction
  hypothesis we have $\v{⟦v⟧} ∈ \ts{A}$ and $\v{⟦v⟧} ≠ \v{□}$.
  Thanks to our second induction hypothesis combined with
  \theorem("main") we obtain $\v{⟦v⟧} ∈ \vs{[(Ci:Ai)i∈I]∧γ₀}$
  and thus we know that the ordinals of $γ₀$ are all positive
  as otherwise this would imply $\v{⟦v⟧} ≠ \v{□}$. As a
  consequence, we have $\vs{[(Ci:Ai)i∈I]∧γ₀} = \vs{[(Ci:Ai)i∈I]}$
  and we can finish the proof as in the case of ($+_e$) rule
  since we can use the remaining induction hypotheses.
  \begin{center}
    $\id(r_sum_ord_e)$
  \end{center}

\item In the case of the ($Y$) rule, we need to show $\t{λx Y(λr t, x)}
  ⊩ C$. Using the second induction hypothesis it is enough to show
  $\t{λx Y(λr t, x)} ⊩ \f{γ₀↪(A⇒B)}$. As for the ($⇒_{i,κ}$) case, if
  $γ₀$ contains some ordinal that is equal to $0$ then we can conclude
  immediately. We can thus assume that all the ordinals of $γ₀$ are
  positive, which means that we can use the right induction hypothesis
  and that we have $\vs{γ₀↪(A⇒B)} = \vs{A⇒B}$. We need to prove
  $\t{λx Y(λr ⟦t⟧, x)} ∈ \ts{A⇒B}$ for which it is enough to show
  $\t{λx Y(λr ⟦t⟧, x)} ∈ \vs{A⇒B}$ according to \theorem("main"). By
  definition, we need to take a value $v ∈ {\vs{A} ∖ \{\v{□}\}}$ and show
  $\t{Y(λr ⟦t⟧, v)} ∈ \ts{B}$. We thus take $π ∈ \ss{B}$ and we
  prove $\p{Y(λr ⟦t⟧, v) ∗ π} ∈ \dbot$. As $\dbot$ is $({↠})$-saturated 
  and we have $\p{Y(λr ⟦t⟧, v) ∗ π} ↠^{∗} \p{⟦t[r≔λx Y(λr t, x)]⟧ ∗ v·π}$
  we only need to show $\p{⟦t[r≔λx Y(λr t, x)]⟧ ∗ v·π} ∈ \dbot$.
  According to our first induction hypothesis it only remains to show
  that we have $\s{v·π} ∈ \ss{A⇒B}$. This follows easily from the fact
  that $v ∈ {\vs{A} ∖ \{\v{□}\}}$ and that $π ∈ \ss{B}$.
  \begin{center}
    $\id(r_fix)$
  \end{center}
\end{itemize}
\end{proof}
\end{thm}

Even with all the new rules introduced in this section, the system is still
not quite ready to be usable. In fact, a notion of circular proofs and
an associated notion of well-foundedness needs to be introduced in the
system. It is possible to apply the framework defined in
\id(citen "Lepigre2017" "Section 3") to obtain circular proofs because
the syntax used for ordinals is exactly the same as ours, and the system
presented in the paper requires a very similar construction.
(* *)
After obtaining a notion of circular proofs, it would be possible to
extend \theorem("uselessadequacy") so that it is proved by ordinal
induction on the circular proofs, provided that they have been show
well-founded. We do not go into the details here for lack of time as
this is still a work in progress.

=<

=<
