\Caml(
open Diagrams
open ProofTree
open LCKAM.Lang
open Lang
)
\Include{Macros}

=> Untyped calculus and abstract machine \label("calculus")

In this chapter, we introduce the programming language that will be
considered throughout this thesis. Its operational semantics is expressed
in terms of an abstract machine, which will allow us to account for
computational effects.

=> The pure $λ$-calculus

In this thesis, we consider a programming language of the ML family, similar
to OCaml or SML. Like every functional language, its syntax is based on the
$λ$-calculus. Introduced by Alonzo Church in the Thirties, the $λ$-calculus
\cite("Church1941") is a formalism for representing computable functions, and
in particular recursive functions. As shown by Alan Turing, the $λ$-calculus
is a //universal model of computation// \cite("Turing1937").

(* The language of λ-terms. *)
\begin{def}\label("deflambda")
The terms of the $λ$-calculus (or $λ$-terms) are built from a countable
alphabet of variables (or $λ$-variables) denoted $\cal{V}_ι=\{x,y,z...\}$.
The set of all the $λ$-terms is denoted $Λ$ and is defined as the language
recognised by the following ||bnf|| grammar.
\Caml(
let _ = sidenote
  << $t,u ::= x \| \t("λx t") \| \t("t u")$ >>
  << $x ∈ \cal{V}_ι$ >>
)
A term of the form $\t("λx t")$ is called an abstraction (or
$λ$-abstractions) and a term of the form $\t("t u")$ is called an
application.
\end{def}
Intuitively, a $λ$-abstraction $\t("λx t")$ forms a function by binding
the variable $x$ in the term $t$. This would be denoted $x ↦ t$ in common
mathematics. Similarly, a term of the form $\t("t u")$ denotes the
application of (the function) $t$ to (the argument) $u$. This would be
denoted $t(u)$ in common mathematics. 
\begin{rem}
As $λ$-terms have a tree-like structure, parenthesis are sometimes required
for disambiguation. For example, the term $\t("λx t u")$ can be read both
as $\t("(λx t) u")$ and as $\t("λx (t u)")$. To lighten the notations
we will consider application to be left-associative and abstraction to bind
stronger that application. As a consequence, we will always read the term
$\t("λx t x u")$ as $\t("λx ((t x) u)")$.
\end{rem}
\begin{rem}
The syntax of the $λ$-calculus only allows for one-place functions. To form
a function of two arguments (or more) one must rely on Curryfication.
Indeed, a function of two arguments can be seen as a function of one
argument returning a function. Following this scheme, the multiple arguments
of the function are given in turn, and not simultaneously. As an example,
the function $(x,y) ↦ x$ can be encoded as $\t("λx λy x")$.
\end{rem}

Although this is not reflected explicitly in the syntax of $λ$-terms,
a $λ$-variable may play two very different roles. It can be used either as
a constant, like $y$ in the constant function $\t("λx y")$, or as a
reference to a binder, like $x$ in the identity function $\t("λx x")$.
Variable binding and the associated notions of free and bound variable are
hence essential.
\begin{def}\label("freelvars")
Given a term $t$, we denote by $FV_ι(t)$ the set of its free $λ$-variables
and $BV_ι(t)$ the set of its bound $λ$-variables. These sets are defined
inductively on the structure of the term $t$.
\begin{center}
\linesBefore(4)
\diagram(
let contents = two_cols
 [ [ <$ FV_ι(x) $>
   ; <$ = $>; <$ \{x\} $> ]
 ; [ <$ FV_ι(\t("λx t")) $>
   ; <$ = $>; <$ FV_ι(t) \setminus \{x\} $> ]
 ; [ <$ FV_ι(\t("t u")) $>
   ; <$ = $>; <$ FV_ι(t) ∪ FV_ι(u) $> ]
 ; [ <$ BV_ι(x) $>
   ; <$ = $>; <$ ∅ $> ]
 ; [ <$ BV_ι(\t("λx t")) $>
   ; <$ = $>; <$ BV_ι(t) ∪ \{x\} $> ]
 ; [ <$ BV_ι(\t("t u")) $>
   ; <$ = $>; <$ BV_ι(t) ∪ BV_ι(u) $> ] ]
let _ = array [`East; `Main; `West; `East; `Main; `West] contents
          ~horizontal_padding:(fun n -> if n = 3 then 10.0 else 1.0)
)
\end{center}
\end{def}
\begin{rem}
Nothing prevents a $λ$-variable to have both free and bound occurrences in
a term. For example, in $t = \t("λx y λy x y")$ the first occurrence of
$y$ is free while its second occurrence is bound.
We have $y ∈ FV_ι(t) = \{y\}$ and $y ∈ BV_ι(t) = \{x, y\}$.
\end{rem}

(* Substitution, α-equivalence and β-reduction. *)
When a $λ$-abstraction (i.e. a function) is applied to an argument, we
obtain a term of the form $\t("(λx t) u")$, called a $β$-redex. The
reduction of such $β$-redexes plays an essential role in computation.
Intuitively, the reduction of the $β$-redex $\t("(λx t) u")$ will be
performed by replacing every occurrence of the bound variable $x$ by $u$ in
the term $t$. This operation, called substitution, is formally defined as
follows.
\begin{def}
Let $t ∈ Λ$ and $u ∈ Λ$ be two $λ$-terms, and $x ∈ \cal{V}_ι$ be a
$λ$-variable. We denote $\lterm("t[x ← u]")$ the term $t$ in which every
free occurrence of $x$ has been replaced by $u$. This operation is defined
inductively on the structure of $t$.
\begin{center}
\linesBefore(5)
\diagram(
let contents =
  let line l r = [ <$ \lterm(l) $> ; <$ = $> ; <$ \lterm(r) $> ] in
  let data =
    [ line "x[x ← u]"       "u"
    ; line "y[x ← u]"       "y"
    ; line "(λx t)[x ← u]"  "λx t"
    ; line "(λy t)[x ← u]"  "λy t[x ← u]"
    ; line "(t₁ t₂)[x ← u]" "t₁[x ← u] t₂[x ← u]" ]
  in two_cols data

let _ =
  array [`East; `Main; `West; `East; `Main; `West] contents
    ~horizontal_padding:(fun n -> if n = 3 then 10.0 else 1.0)
)
\end{center}
\end{def}
Substitution is a subtle notion, and care should be taken to avoid capture
of variables. For example, let us consider the function $\lterm("λx λy x")$
which takes an argument $x$ and returns a constant function with value $x$.
If we apply this function to $y$, the expected result is a constant function
with value $y$. However, if we blindly substitute $x$ with $y$ in
$\lterm("λy x")$ we obtain the identity function $\lterm("λy y")$. Indeed,
the free variable $y$ has been captured and now references a binder that had
(coincidentally) the same name.

To solve this problem, we need to make sure that whenever a substitution
$\lterm("t[x ← u]")$ is performed, no free variable of $u$ is bound in $t$
(i.e. $FV_ι(u) ∩ BV_ι(t) = ∅$). Although we cannot rename the free variables
of $u$, it is possible to rename the bound variables of $t$. Indeed, changing
the name of a bound variable has no effect on the computational behaviour of
a term. Two terms that are equivalent up to the names of their bound
variables are said to be $α$-equivalent.
\begin{def}
The $α$-equivalence relation $({≡}_α) ⊆ Λ×Λ$ is defined, like in
\cite("Krivine1990"), as the smallest relation such that:
\begin{itemize}
\item if $x ∈ \cal{V}_ι$ then $x ≡_α x$,
\item if $t₁ ≡_α t₂$ and $u₁ ≡_α u₂$ then
      $\lterm("t₁ u₁") ≡_α \lterm("t₂ u₂")$,
\item if $\lterm("t₁[x₁ ← y]") \nequiv_α \lterm("t₂[x₂ ← y]")$ for only
      finitely many $y ∈ \cal{V}_ι$ then
      $\lterm("λx₁ t₁") ≡_α \lterm("λx₂ t₂")$.
\end{itemize}
\end{def}
\begin{lem}\label("alphalem")
Given a term $t ∈ Λ$ and a finite set of variables $V ⊆ \cal{V}_ι$, it is
always possible to find a term $t₀ ∈ Λ$ such that $t₀ ≡_α t$ and
$BV_ι(t₀) ∩ V = ∅$.
\begin{proof}
A full proof is available in \id(dcite "Krivine1990" "Lemma 1.11").
\end{proof}
\end{lem}
\begin{def}
Let $t ∈ Λ$ and $u ∈ Λ$ be two $λ$-terms, and $x ∈ \cal{V}_ι$ be a
$λ$-variable. We denote $\lterm("t[x ≔ u]")$ the capture-avoiding
substitution of $x$ by $u$ in $t$. It is defined as $\lterm("t₀[x ← u]")$
where $t₀ ∈ Λ$ is a term such that $t₀ ≡_α t$ and $BV_ι(t₀) ∩ FV(u) = ∅$.
Such a term exists according to \lemma("alphalem").
\end{def}

=<

=> Evaluation contexts and reduction

To define the most general notion of reduction over $λ$-terms, we
need to be able to refer to any $β$-redex. To this aim, we
introduce the notion of evaluation context. Intuitively, a context will
consist in a term with a hole (i.e. a place-holder for a subterm) and it
will allow us to focus on any particular subterm of a term.
\begin{def}
The set of evaluation contexts $[Λ]$ is defined as the language recognised
by the following ||bnf|| grammar.
\Caml(
let _ = sidenote
  << $E, F ::= \lctxt("[]") \| \lctxt("λx E") \| \lctxt("E t") \|
     \lctxt("t E")$ >>
  << $x∈\cal{V}_ι$, $t∈Λ$ >>
)
\end{def}
\begin{def}
Given a term $u ∈ Λ$ and an evaluation context $E ∈ [Λ]$, we denote
$\lterm("E[u]")$ the term formed by putting $u$ into the hole of the
evaluation context $E$. It is defined by induction on the structure of
$E$ as follows.
\begin{center}
\diagram(
let contents =
  let line l r = [ <$ \lterm(l) $> ; <$ = $> ; <$ \lterm(r) $> ] in
  let data =
    [ line "[][u]"     "u"
    ; line "(λx E)[u]" "λx E[u]"
    ; line "(E t)[u]"  "E[u] t"
    ; line "(t E)[u]"  "t E[u]" ]
  in two_cols data
let _ =
  array [`East; `Main; `West; `East; `Main; `West] contents
    ~horizontal_padding:(fun n -> if n = 3 then 10.0 else 1.0)
)
\end{center}
\end{def}
\begin{rem}
Note that free variables of a term $u$ may be captured when forming
$\lterm("E[u]")$. For example, if we take $u = x$ and
$E = \lctxt("λx λy []")$ then $x$ is free in $u$, but it does not
appear free in $\lterm("E[u]") = \lterm("λx λy x")$.
\end{rem}
\begin{def}
Given a set of evaluation context $C ⊆ [Λ]$, we denote $\cal{R}(C) ⊆ Λ×Λ$
the $β$-reduction relation induced by $C$. It is defined as the smallest
relation such that for every $E ∈ C$, for every terms $t ∈ Λ$ and $u ∈ Λ$,
and for every variable $x ∈ \cal{V}_ι$ we have the following.
$$ (\lterm("E[(λx t) u]"), \lterm("E[t[x ≔ u]]")) ∈ \cal{R}(C) $$
\end{def}
\begin{def}\label("generalbeta")
The general $β$-reduction $({→}_β) ⊆ Λ×Λ$ is defined as $\cal{R}([Λ])$. We
say that the term $t ∈ Λ$ is in $β$-normal-form if there is no $u ∈ Λ$ such
that $t →_β u$. We denote $({→}_β^{∗})$ the reflexive, transitive closure of
$({→}_β)$.
\end{def}

The general $β$-reduction relation $({→}_β)$ is non-deterministic. Indeed,
given a term $t$, there might be two (different) terms $u₁$ and $u₂$ such
that $t →_β u₁$ and $t →_β u₂$. For example,
$\lterm("((λx₁ x₁) λx₂ x₂) ((λx₃ x₃) λx₄ x₄)")$ can either reduce to
$\lterm("(λx₂ x₂) ((λx₃ x₃) λx₄ x₄)")$ or to
$\lterm("((λx₁ x₁) λx₂ x₂) (λx₄ x₄)")$. Indeed, we can focus on the $β$-redex
$\lterm("(λx₁ x₁) λx₂ x₂")$ using the evaluation context
$\lctxt("[] ((λx₃ x₃) λx₄ x₄)")$, or on the $β$-redex
$\lterm("(λx₃ x₃) λx₄ x₄")$ using the evaluation context
$\lctxt("((λx₁ x₁) λx₂ x₂) []")$.
Although it is non-deterministic, the general $β$-reduction relation
$({→}_β)$ has the Church-Rosser property \cite("Church1936").
\begin{thm}
Let $t ∈ Λ$ be a term. If there are $u₁ ∈ Λ$ and $u₂ ∈ Λ$ such that
$t →_β u₁$ and $t →_β u₂$, then there must be $u ∈ Λ$ such that
${u₁ →_β u}^{∗}$ and ${u₂ →_β u}^{∗}$.
\begin{proof}
A full proof is available in \cite("Church1936") or \cite("Barendregt1981")
for example.
\end{proof}
\end{thm}
Intuitively, the Church-Rosser property enforces a weak form of determinism.
Indeed, it implies that a program can only compute one particular result,
even if it can be attained in several different ways.

In the following, we are going to consider an effectful language, that does
not have the Church-Rosser property. As a consequence, we will need to
restrict ourselves to a deterministic subset of the general $β$-reduction
relation. If we were to work with a completely non-deterministic reduction
relation, it would be extremely difficult to reason about our language.
Programs would not only compute different possible results, but also
terminate in a non-deterministic way. (* Moreover, it would be silly to
implement a non-deterministic evaluation procedure for a programming
language. *)

The choice of the order in which $β$-redexes are reduced is called an
//evaluation strategy//. The two evaluation strategies that are the most
widely used in practice are called //call-by-name// and //call-by-value//.
They both reduce outermost $β$-redexes first, and do not reduce $β$-redexes
that are contained in the body of a $λ$-abstraction. This means that the
term $\lterm("λx (λy y) x")$ is considered to be in normal form and cannot
be evaluated further. In call-by-name, terms that are in function position
are reduced first, and the computation of their arguments is delayed to the
time of their effective use. In call-by-value, both arguments and functions
are evaluated before performing the $β$-reduction. One way to formalize
these evaluation strategies is to restrict the notion of evaluation context,
to only allow focusing on the $β$-redex that is going to be reduced next.
\begin{def}
The set of call-by-name evaluation contexts $[N] ⊆ [Λ]$ is defined as the
language recognised by the following ||bnf|| grammar.
\Caml(
let _ = sidenote
  << $E, F ::= \lctxt("[]") \| \lctxt("E t") $ >>
  << $t∈Λ$ >>
)
The call-by-name reduction relation $({→}_N) ⊆ Λ×Λ$ is defined as
$\cal{R}([N])$.
\end{def}

In call-by-value, both the function and its argument need to be fully
evaluated before the application can be performed. Consequently, two
different call-by-value strategies can be defined: left-to-right and
right-to-left call-by-value evaluation. The former fully evaluates the
terms that are in function position first and the latter evaluates the
terms that are in argument position first. Although left-to-right
call-by-value evaluation is most widely used, some practical languages
like OCaml use right-to-left evaluation. In this thesis, we make the
same choice and only consider right-to-left call-by-value evaluation.
\begin{def}
A term $t$ is said to be a value if it is either a $λ$-variable or a
$λ$-abstraction. The set $Λ_ι ⊆ Λ$ of all the values is generated by the
following ||bnf|| grammar.
\Caml(
let _ = sidenote
  << $v,w ::= x \| \lterm("λx t") $ >>
  << $x ∈ \cal{V}_ι$ >>
)
\end{def}
\begin{def}
The set of right-to-left call-by-value evaluation contexts $[V] ⊆ [Λ]$ is
defined as the language recognised by the following ||bnf|| grammar.
\Caml(
let _ = sidenote
  << $E, F ::= \lctxt("[]") \| \lctxt("E v") \| \lctxt("t E") $ >>
  << $v∈Λ_ι$, $t∈Λ$ >>
)
The right-to-left call-by-value reduction relation $({→}_V) ⊆ Λ×Λ$ is
defined as $\cal{R}([V])$.
\end{def}
\begin{rem}
Left-to-right call-by-value evaluation can be defined using evaluation
contexts generated by the following ||bnf|| grammar.
\Caml(
let _ = sidenote
  << $E, F ::= \lctxt("[]") \| \lctxt("E t") \| \lctxt("v E") $ >>
  << $t∈Λ$, $v∈Λ_ι$ >>
)
\end{rem}

A given term of the $λ$-calculus may reduce in a very different way with
different evaluation strategies. For example, the evaluation of the term
$\lterm("(λy z) ((λx x x) (λx x x))")$ stops in one step in call-by-name
$$ \lterm("(λy z) ((λx x x) (λx x x))") →_N \lterm("z") $$
and it goes into a loop in call-by-value.
$$ \lterm("(λy z) ((λx x x) (λx x x))") →_V
   \lterm("(λy z) ((λx x x) (λx x x))") $$

\begin{rem}
Our reduction relations can be alternatively defined using a deduction rule
system. A deduction rule is formed using premisses $\{P_i\}_{1≤i≤n}$ and
a conclusion $C$ separated by an horizontal bar.
$$ \ternaryR{P₁}{...}{P_n}{C} $$
The meaning of such a rules is that the conclusion $C$ can be deduced when
all the premisses $P_i$ are true. In particular, if there is no premise then
the conclusion can be deduced immediately. Using this formalism, the
call-by-name reduction corresponds to the smallest relation satisfying the
following two rules.
$$
  \axiomR{\lterm("(λx t) u") →_N \lterm("t[x ≔ u]")}
  \hspace(6.0)
  \unaryR{\lterm("t₁") →_N \lterm("t₂")}{\lterm("t₁ u") →_N \lterm("t₂ u")}
$$
Similarly, the right-to-left call-by-value reduction relation $({→}_V)$
corresponds to the smallest relation satisfying the following three rules.
$$
  \axiomR{\lterm("(λx t) v") →_V \lterm("t[x ≔ v]")}
  \hspace(4.0)
  \unaryR{\lterm("u₁") →_V \lterm("u₂")}{\lterm("t u₁") →_V \lterm("t u₂")}
  \hspace(4.0)
  \unaryR{\lterm("t₁") →_V \lterm("t₂")}{\lterm("t₁ v") →_V \lterm("t₂ v")}
$$
\end{rem}

In this thesis, $λ$-terms and programs in general will be evaluated in an
abstract machine called a Krivine machine \cite("Krivine2007"). This
machine will emulate the right-to-left evaluation relation $({→}_V)$. It
will provide us with a computational framework in which programs and their
evaluation contexts can be manipulated easily.

=<

=> Call-by-value Krivine machine

In the previous section, we introduced the syntax of the $λ$-calculus and
the evaluation of $λ$-terms. We will now reformulate these definition in
terms of a call-by-value Krivine abstract machine \cite("Krivine2007").
Our presentation will differ from the original machine, which is
call-by-name. Although call-by-value Krivine machines have rarely been
published, they are well-known in the classical realizability and compiler
communities.

The main idea behind the Krivine abstract machine is to think of a term
$\t("t₀") ∈ Λ$ as a couple $(\t("t"),\c("E")) ∈ Λ × [V]$ such that
$\t("t₀") = \t("E[t]")$ (the term $\t("t")$ is said to be in head position).
Using this reprensentation, $β$-reduction proceeds in two steps. First, the
machine state $(\t("t"), \c("E"))$ is transformed into a state of the form
$(\t("(λx u) v"), \c("F"))$, in such a way that
$\t("E[t]") = \t("F[(λx u) v]")$. The $β$-redex can then be reduced to
obtain the state $(\t("u[x ≔ v]"), \c("F"))$. This behaviour can be attained
using the following reduction rules, which are obtained naturally from the
definition of right-to-left call-by-value evaluation.
\Caml(
  let _ =
    let line (t1, c1) (t2, c2) n =
      (<<$(\t(t1), \c(c1))$>>, <<$(\t(t2), \c(c2))$>>, n)
    in
    reduction_def <<$→$>>
      [ line ("t u", "E"      ) ("u"  , "E[t []]") <<when $u∉Λ_ι$>>
      ; line ("v"  , "E[t []]") ("t v", "E"      ) []
      ; line ("t v", "E"      ) ("t"  , "E[[] v]") <<when $t∉Λ_ι$>>
      ; line ("v"  , "E[[] w]") ("v w", "E"      ) []
      ; line ("(λx t) v", "E" ) ("t[x ≔ v]", "E" ) [] ]
)
The four first rules are responsible for bringing the next $β$-redex
(according to our reduction strategy) in head position, and the last
rule performs the $β$-reduction. Note that the first four rules do not
change the represented term, and only move arguments or functions between
the term and the evaluation context. Our set of reduction rules can be
simplified to the following, by composing the last two pairs of rules.
\Caml(
  let _ =
    let line (t1, c1) (t2, c2) =
      (<<$(\t(t1), \c(c1))$>>, <<$(\t(t2), \c(c2))$>>, [])
    in
    reduction_def <<$→$>>
      [ line ("t u" , "E"      ) ("u"       , "E[t []]")
      ; line ("v"   , "E[t []]") ("t"       , "E[[] v]")
      ; line ("λx t", "E[[] v]") ("t[x ≔ v]", "E"      ) ]
)
The first rule is used to focus on the argument of an application, to compute
it first. When the argument has been evaluated to a value, the second rule
can be used to swap the argument with the unevaluated function. The
computation can then continue with the evaluation of the function, which
should (hopefully) evaluate to a $λ$-abstraction. If it is the case, the
third rule can be applied to actually perform the $β$-reduction.

The state of the abstract machine can be seen as a zipper \cite("Huet1997")
on the tree structure of a term. Indeed, the term that is in head position
is the subterm on which the machine is focusing. It is also worth noting
that the machine manipulates evaluation contexts from the inside out, which
results in a heavy syntax. However, it is possible to represent right-to-left
call-by-value evaluation contexts using a stack of functions (i.e. terms)
and argument (i.e. values). We will take this approach in the following.
\begin{def}
Values, terms, stacks and processes are generated by the following four
||bnf|| grammars. The names of the corresponding sets are displayed on
the left.
\Caml(
let _ =
  let line a b c d = (a,b,c,d) in
  bnfs
  [ line <<$(Λ_ι)$>> <<$v, w$>>
         <<$\v("x") \| \v("λx t")$>> <<$x∈\cal{V}_ι$>>
  ; line <<$(Λ)$>> <<$t, u$>> <<$\t("v") \| \t("t u")$>> []
  ; line <<$(Π)$>> <<$π, ξ$>> <<$\s("ε") \| \s("v·π") \| \s("[t]π")$>> []
  ; line <<$(Λ × Π)$>> <<$p, q$>> <<$\p("t ∗ π")$>> [] ]
)
\end{def}
The syntactic distinction between terms and values is specific to the
call-by-value presentation, they would be collapsed in call-by-name.
Intuitively, a stack can be thought of as an evaluation context represented
as a list of terms and values. The values can be seen as arguments to be fed
to the term in the context, and the terms can be considered as functions
to which the term in the context will be applied. The symbol $ε$ is used to
denote an empty stack. A process $\p("t ∗ π")$ forms the state of our
abstract machine, and its reduction will consist in the interaction between
the term $t$ and its evaluation context encoded into the stack $π$.

Since our calculus is call-by-value, only values are (and should be)
substituted to $λ$-variables during evaluation. From now on, we will hence
work with the following definition of substitution. In particular, a
substitution of the form $\lterm("t[x ≔ u]")$ will be forbidden if $u$ is
not a syntactic value.
\begin{def}
Let $t ∈ Λ$ be a term, $x ∈ \cal{V}_ι$ be a $λ$-variable and $v ∈ Λ_ι$
be a value. We denote $\t("t[x ≔ v]")$ the capture-avoiding substitution
of $x$ by $v$ in $t$.
\end{def}
\begin{def}
The reduction relation $({≻}) ⊆ (Λ×Π) × (Λ×Π)$ is the smallest relation
satisfying the following rules. We denote $({≻}^{∗})$ its reflexive and
transitive closure.
\Caml(
  let _ =
    let line p1 p2 =
      (<<$\p(p1)$>>, <<$\p(p2)$>>, [])
    in
    reduction_def <<$≻$>>
      [ line "t u ∗ π"    "u ∗ [t]π"
      ; line "v ∗ [t] π"  "t ∗ v·π"
      ; line "λx t ∗ v·π" "t[x ≔ v] ∗ π" ]
)
\end{def}
Three reduction rules are used to handle call-by-value evaluation. When an
application is encountered, the function is stored in a stack-frame in order
to evaluate its argument first. Once the argument has been completely
computed, a value faces the stack-frame containing the function. At this
point the function can be evaluated and the value is stored in the stack,
ready to be consumed by the function as soon as it evaluates to a
$λ$-abstraction. A capture-avoiding substitution can then be performed to
effectively apply the argument to the function. As an example, the process
$\p("(λx x y) λz z ∗ ε")$ reduces to $\p("y ∗ ε")$ in the following way, and
cannot evaluate further.
\begin{center}
\linesBefore(8)
\diagram(
let _ =
  let line s = [ []; <$≻$>; <$\p(s)$> ] in
  array [`East ; `East ; `West]
  [ [ <$\p("(λx x y) λz z ∗ ε")$>; <$≻$>; <$\p("λz z ∗ [λx x y]ε")$> ]
  ; line "λx x y ∗ λz z · ε"
  ; line "(λz z) y ∗ ε"
  ; line "y ∗ [λz z] ε"
  ; line "λz z ∗ y · ε"
  ; line "y ∗ ε" ]
)
\end{center}

\begin{rem}
It is possible to prove that the abstract machine and its $({≻})$ reduction
relation indeed implement the $({→}_v)$ evaluation on $λ$-terms. Although it
is not included here, this result has been formalized by the author using
the //Coq// proof assistant \cite("CoqTeam2004"). The proof sketch is
distributed with this document (see the file ##correction##.##v##).
\end{rem}

\begin{rem}
A left-to-right call-by-value machine could be defined in a similar way, but
the roles of terms and values would be swapped in stacks. Stack frames would
contain values, terms would be pushed on stacks, and the reduction relation
would be as follows.
\Caml(
  let _ =
    let line p1 p2 =
      (<<$\proc(p1)$>>, <<$\proc(p2)$>>, [])
    in
    reduction_def <<$≻_{RL}$>>
      [ line "t u ∗ π"     "t ∗ u·π"
      ; line "v ∗ u·π"     "u ∗ [v]π"
      ; line "v ∗ [λx t]π" "t[x ≔ v] ∗ π" ]
)
\end{rem}

The state of our abstract machine contains two parts: a term being evaluated
(i.e. the term in head position) and its evaluation context (i.e. the stack).
As a consequence, it is possible to define reduction rules that manipulate
the stack (i.e. the evaluation context) as a first class object. Such
reduction rules produce computational effects.

=<

=> Computational effects and \lmcalc

In the programming languages community, computational effects (a.k.a.
side-effect) refer to modifications made by a program to its environment
as a byproduct of the computation of its result. For example, a program
may generate computational effects by writing to a tape, or by modifying
the value of a global memory cell. In our calculus, the environment of a
program (i.e. a term) only consists in an evaluation context encoded as
a stack. Computational effects can hence be produced if a program is able
to modify the stack as a whole during its evaluation in the abstract
machine.

We are now going to extend our calculus and our abstract machine with
operations allowing the manipulation of the stack. More precisely, we
will provide a way to save the stack (i.e. the evaluation context), so
that it can be restored at a later stage. A natural way to extend our
language is to use the syntax of Michel Parigot's \lmcalc
\cite("Parigot1992"). We hence introduce a new binder $\t("μα t")$
capturing the current stack in the $μ$-variable $α$. The stack can then
be restored in $t$ using the syntax $\t("[α]u")$.
\begin{def}
Let $\cal{V}_σ = \{α, β, γ...\}$ be a countable set of $μ$-variables (or
stack variables) disjoint from $\cal{V}_ι$. Value, terms, stacks and
processes are now generated by the following grammars. The names of the
corresponding sets are displayed on the left.
\Caml(
let _ = bnfs
  [ ( << $(Λ_ι)$ >>
    , << $v, w$ >>
    , << $\v("x") \| \v("λx t")$ >>
    , << $x∈\cal{V}_ι$ >> )
  ; ( << $(Λ)$ >>
    , << $t, u$ >>
    , << $\t("v") \| \t("t u") \| \t("μα t") \| \t("[π]t")$ >>
    , [] )
  ; ( << $(Π)$ >>
    , << $π, ξ$ >>
    , << $\s("ε") \| \s("α") \| \s("v·π") \| \s("[t]π")$ >>
    , << $α∈\cal{V}_σ$ >> )
  ; ( << $(Λ × Π)$ >>
    , << $p, q$ >>
    , << $\p("t ∗ π")$ >>
    , [] ) ]
)
\end{def}
Note that terms of the form $\t("[π]t")$ will only be available to the user
if $π$ is a stack variable. Allowing arbitrary stacks allow us to substitute
$μ$-variables by stacks during computation. Like with $λ$-variable, we will
need to be careful and avoid variable capture. However, we will not give
the full details this time.
\begin{def}
Given a value, term, stack or process $ψ$, we denote $FV_ι(ψ)$ (resp.
$BV_ι(ψ)$) the set of its free (resp. bound) $λ$-variables and $FV_σ(ψ)$
(resp. $BV_σ(ψ)$) the set of its free (resp. bound) $μ$-variables. These
sets are defined in a similar way to \definition("freelvars").
\end{def}
\begin{def}
Let $t ∈ Λ$ be a term, $π ∈ Π$ be a stack and $α ∈ \cal{V}_σ$ be a
$μ$-variable. We denote $\t("t[α ≔ π]")$ the (capture-avoiding) substitution
of $α$ by $π$ in $t$.
\end{def}
\begin{def}
The reduction relation $({≻})$ is extended with two new reduction rules.
\Caml(
  let _ =
    let line p1 p2 =
      (<<$\p(p1)$>>, <<$\p(p2)$>>, [])
    in
    reduction_def <<$≻$>>
      [ line "t u ∗ π"      "u ∗ [t]π"
      ; line "v ∗ [t] π"    "t ∗ v · π"
      ; line "λx t ∗ v · π" "t[x ≔ v] ∗ π"
      ; line "μα t ∗ π"     "t[α ≔ π] ∗ π"
      ; line "[ξ]t ∗ π"     "t ∗ ξ" ]
)
\end{def}
When the abstract machine encounters a $μ$-abstraction $\t("μα t")$, the
current stack $π$ is substituted to the $μ$-variables $α$. Consequently,
every subterm of the form $\t("[α]u")$ in $t$ becomes $\t("[π]u")$. When the
machine then reaches a state of the form $\p("[ξ]u ∗ π")$, the current stack
$π$ is erased, and computation resumes with the stored stack $ξ$. For
example, if $t$ and $v$ are arbitrary terms and values, then the process
$\p("λx μα t [α]x ∗ v·ε")$ reduces as follows.
\Caml(
  let _ =
    let first p1 p2 = (<<$\p(p1)$>>, <<$\p(p2)$>>, []) in
    let line p1 = ([], <<$\p(p1)$>>, []) in
    reduction_def ~pad:1.5 <<$≻$>>
      [ first "λx μα t [α]x ∗ v·ε" "μα t[x ≔ v] [α]v ∗ ε"
      ; line "t[x ≔ v] [ε]v ∗ ε"
      ; line "[ε]v ∗ [t[x ≔ v]]ε"
      ; line "v ∗ ε" ]
)
Note that when a stack is erased, arbitrary terms might be erased. In
particular, we could have chosen $t = Ω = \t("(λx x x) λx x x")$ in the
previous example, although the reduction of this term does not terminate.
Indeed, we have
\begin{center}
\linesBefore(4)
\diagram(
let _ =
  let line s = [ []; <$≻$>; <$\p(s)$> ] in
  array [`East ; `East ; `West]
  [ [ <$\p("Ω ∗ π")$>; <$≻$>; <$\p("λx x x ∗ [λx x x] π")$> ]
  ; line "λx x x ∗ λx x x · π"
  ; line "Ω ∗ π" ]
)
\end{center}
for every possible stack $π$.

The abstract machine defined in this section can be used for evaluating
terms of the \lmcalc. Although this language is very elegant and concise,
it is not suitable for practical programming. In the following section,
our language will be extend with records (i.e. tuples with named fields)
and variants (i.e. constructors and pattern-matching). Consequently, we
will obtain a simple language with a concise formal definition, but that
will be closer to being a practical programming language.

=<

=> Full syntax and operational semantics

In this section, we present the syntax and the reduction relation of the
abstract machine that will be considered throughout this thesis. Although
the following extends definitions given in the previous sections, we
choose not to avoid repetitions so that this section remains completely
self-contained.

In this thesis, we consider a language that is expressed in terms of a
//Krivine Abstract Machine// \cite("Krivine2007"). As our machine has the
specificity of being call-by-value, which requires a syntax formed with
four entities: values, terms, stacks and processes. Note that the
distinction between terms and values is specific to our call-by-value
presentation, they would be collapsed in call-by-name.
\begin{def}
We require three distinct, countable sets of variables:
$\cal{V}_ι = \{x, y, z...\}$ for $λ$-variables,
$\cal{V}_σ = \{α, β, γ...\}$ for $μ$-variables and
$\cal{V}_τ = \{a, b, c...\}$ for term variables.
We also require a countable set $\cal{L} = \{l, k...\}$ of labels to
name record fields and a countable set $\cal{C} = \{C, D...\}$ for
naming variants (a.k.a. constructors).
\end{def}
As usual, $λ$-variables and $μ$-variables will be bound in terms to
respectively form functions and capture continuations. As our calculus
will not provide binders ranging over term variables, they will only
appear free.

\begin{def}
Values, terms, stacks and processes are mutually inductively defined as the
languages recognised by the following ||bnf|| grammars. The names of the
corresponding sets are displayed on the left.
\Caml(
let _ = large_bnfs
  [ ( << $(Λ_ι)$ >>
    , << $v, w$ >>
    , << $\v("x") \| \v("λx t") \| \v("C[v]") \| \v("{(li = vi) i∈I}")$ >> )
  ; ( << $(Λ)$ >>
    , << $t, u$ >>
    , << $\t("a") \| \t("v") \| \t("t u") \| \t("μα t") \| \t("[π]t")
         \| \t("v.l") \| \t("[v | (Ci[xi] → ti) i∈I]") \| \t("Y(t, v)")
         \| \t("U(v)") \| \t("δ(v,w)") $ >> )
  ; ( << $(Π)$ >>
    , << $π, ρ$ >>
    , << $\s("ε") \| \s("α") \| \s("v·π") \| \s("[t]π")$ >> )
  ; ( << $(Λ × Π)$ >>
    , << $p, q$ >>
    , << $\p("t ∗ π")$ >> ) ]
)
Note that $I ⊆_{fin} \bbN$ denotes a finite set of indexes. For any such
set $I$, we will assume that for all $i∈I$ and $j∈I$ such that $i ≠ j$
we have $C_i ≠ C_j$ and $l_i ≠ l_j$.
\end{def}
Terms and values form a variation of the \lmcalc \cite("Parigot1992"),
enriched with ML-like constructs (i.e. records and variants). Values of
the form $\v("C[v]")$ correspond to variants, which always have exactly
one argument in our language. Case analysis on variants is performed using
the syntax $\t("[v | (Ci[xi] → ti) i∈I]")$, in which the pattern
$\v("Ci[xi]")$ is mapped to the term $t_i$ for all $i$ in $I$. Similarly,
values of the form $\v("{(li = vi) i∈I}")$ correspond to records, which are
tuples with named fields. The projection operation $\t("v.l")$ can be used
to access the values stored in a record $v$.
\begin{rem}
The syntax $\t("[v | (Ci[xi] → ti) i∈I]")$ for pattern-matching and the
syntax $\v("{(l = v) i∈I}")$ for records are part of our meta-language. We
only use them as shortcuts to designate arbitrary lists of patterns or
record fields. In the actual syntax, the full list of patterns or fields
always need to be specified. As an example, we would write
$\t("{l₁ = v₁; l₂ = v₂;}")$ for a record or
$\t("[v | C₁[x₁] → t₁ | C₂[x₂] → t₂]")$ for a case analysis if
$I = \{1, 2\}$.
\end{rem}
A term of the form $\t("Y(t,v)")$ denotes a fixpoint combinator, which
roughly corresponds to OCaml's “##let rec##” construct. The terms of the
form $\t("U(v)")$ of $\t("δ(v,w)")$ are only included for technical purposes
and are not intended to be used for programming. The former will allow us to
distinguish the empty record $\v("{}")$ from $λ$-abstractions in our
definition of observational equivalence (see \chapter("obsEquiv")), and the
latter will be used to obtain an essential property of our realizability
model (see \chapter("semValRest")). (* FIXME obsEquiv *)

A stack can be either the empty stack $ε$, a stack variable, a value pushed
on top of a stack, or a stack frame containing a term on top of a stack.
These two constructors are specific to the call-by-value presentation as a
stack not only needs to store the arguments to functions, but also the
functions themselves while their arguments are being computed. In
call-by-name we would only need to store the arguments to functions in the
stack.
\begin{rem}
We enforce values in constructors, record fields, projections and case
analysis. This makes the calculus simpler because only $β$-reduction need
to manipulate the stack. Syntactic sugars such as the following can be
defined to hide these restrictions.
\Caml(
let sugarproj =
  let open Lang_maths in
  let open Lang_ast in
  t2m (TProj (VMeta ("t", None), ("l", None)))
let sugarcons =
  let open Lang_maths in
  let open Lang_ast in
  t2m (TValu (VCons (("C", None), VMeta ("t", None))))
)
$$
  \sugarproj ≔ \t("(λx x.l) t")
  \hspace(4.0)
  \sugarcons ≔ \t("(λx C[x]) t")
$$
Note that the elimination of such syntactic sugars corresponds to a form
of partial ##let##-normalization \cite("Moggi1989") or ##A##-normalization
\cite("Flanagan1993"). The translation can hence be seen as a natural
compilation step \mcite(["Tarditi1996"; "Chlipala2005"]).
\end{rem}
\begin{def}
Given a value, term, stack or process $ψ$ we denote $FV_ι(ψ)$ (resp.
$FV_σ(ψ)$, $FV_τ(ψ)$) the set of free $λ$-variables (resp. free
$μ$-variables, term variables) contained in $ψ$. We also denote
$BV_ι(ψ)$ (resp. $BV_σ(ψ)$) the set of bound $λ$-variables (resp.
$μ$-variables) contained in $ψ$. We say that $ψ$ is closed if
$FV_ι(ψ) ∪ FV_σ(ψ) ∪ FV_ι(ψ) = ∅$.
\end{def}
(* TODO simultaneous substitution. *)
\begin{def}
Let $ψ$ be a value, term, stack or process. Given a $λ$-variable
$x ∈ \cal{V}_ι$ and a value $w ∈ Λ_ι$, we denote $\p("ψ[x ≔ v]")$
the capture-avoiding substitution of $x$ by $v$ in $ψ$. Given a
$μ$-variable $α ∈ \cal{V}_σ$ and a stack $π ∈ Π$, we denote
$\p("ψ[α ≔ π]")$ the capture-avoiding substitution of $α$ by $π$ in $ψ$.
Given a term variable $a ∈ \cal{V}_ι$ and a term $t ∈ Λ$, we denote
$\p("ψ[a ≔ t]")$ the substitution of $a$ by $t$ in $ψ$.
\end{def}

Processes form the internal state of our abstract machine. They are to be
thought of as a term put in some evaluation context represented using a
stack. Intuitively, the stack $π$ in the process $\p("t ∗ π")$ contains the
arguments to be fed to $t$. Since we are in call-by-value the stack also
handles the storing of functions while their arguments are being evaluated.
This is why we need stack frames (i.e. stacks of the form $\s("[t]π")$). The
operational semantics of our language is given by a relation $({≻})$ over
processes.
\begin{def}
The relation $({≻}) ⊆ (Λ×Π) × (Λ×Π)$ is defined as the smallest relation
satisfying the following reduction rules.
\Caml(
  let _ =
    let line p1 p2 = (<<$\p(p1)$>>, <<$\p(p2)$>>, []) in
    let line' p1 p2 = (<<$\p(p1)$>>, <<$\p(p2)$>>, <<when $k∈I$>>) in
    reduction_def <<$≻$>>
      [ line  "t u ∗ π"                         "u ∗ [t]π"
      ; line  "v ∗ [t]π"                        "t ∗ v·π"
      ; line  "λx t ∗ v·π"                      "t[x ≔ v] ∗ π"
      ; line  "μα t ∗ π"                        "t[α ≔ π] ∗ π"
      ; line  "[ξ]t ∗ π"                        "t ∗ ξ"
      ; line' "{(li = vi) i∈I}.lk ∗ π"          "vk ∗ π"
      ; line' "[Ck[v] | (Ci[xi] → ti) i∈I] ∗ π" "ti[xi≔v] ∗ π"
      ; line  "Y(t,v) ∗ π"                      "t ∗ λx Y(t,x)·v·π"
      ; line  "U({}) ∗ π"                       "{} ∗ π" ]

)
We will denote $({≻}^{+})$ its transitive closure, $({≻}^{∗})$ its
reflexive-transitive closure and $({≻}^k)$ its $k$-fold application.
\end{def}
The first three rules are those that handle $β$-reduction. When the abstract
machine encounters an application, the function is stored in a stack-frame in
order to evaluate its argument first. Once the argument has been completely
computed, a value faces the stack-frame containing the function. At this
point the function can be evaluated and the value is stored in the stack
ready to be consumed by the function as soon as it evaluates to a
$λ$-abstraction. A capture-avoiding substitution can then be performed to
effectively apply the argument to the function. The fourth and fifth rules
rules handle the classical part of computation. When a $μ$-abstraction is
reached, the current stack is captured and substituted for the corresponding
$μ$-variable. Conversely, when a term of the form $\t("[ξ]t")$, the current
stack is discarded and evaluation resumes with the process $\p("t ∗ ξ")$.
In addition to the reduction rules for $β$-reduction and stack manipulation,
we provide reduction rules for handling record projection, case analysis and
recursion using a fixpoint operator.

A last rule is also provided for reducing processes of the form
$\p("U({}) ∗ π")$ to $\p("{} ∗ π")$. Note that for any value $v$ that is not
$\v("{}")$, no reduction rule apply on the process $\p("U(v) ∗ π")$. We will
use this fact in \chapter("obsEquiv") to show that the value $\v("{}")$ have
a different observable computational behaviour to $λ$-abstractions in our
abstract machine.
\begin{rem}
Our reduction relation $({≻})$ does not provide any way of reducing
processes of the form $\p("δ(v,w) ∗ π")$. It will be extended with a
reduction rule for such processes in \chapter("semValRest"). However,
they can be considered as constants for now.
\end{rem}

\begin{lem}\label{redcompatall}
The reduction relation $({≻})$ is compatible with substitutions of variables
of any kind. More formally, if $p$ and $q$ are processes such that $p ≻ q$
then $\p("p[x ≔ v]") ≻ \p("q[x ≔ v]")$ for all $x∈\cal{V}_ι$ and $v∈Λ_ι$.
Similarly, we have $\p("p[α ≔ π]") ≻ \p("q[α ≔ π]")$ for all $α ∈ \cal{V}_σ$
and $π ∈ Π$, and $\p("p[a ≔ t]") ≻ \p("q[a ≔ t]")$ for all $a ∈ \cal{V}_ι$
and $t ∈ Λ$.
\begin{proof}
Case analysis on the reduction rules, all rules being local.
\end{proof}
\end{lem}
\begin{lem}
If $ρ$ is a substitution for variables of any kind and if $p≻q$ (resp.
$p ≻^{∗} q$, $p ≻^{+} q$, $p ≻^k q$) then $\p("pρ") ≻ \p("qρ")$ (resp.
$\p("pρ") ≻^{∗} \p("qρ")$, $\p("pρ") ≻^{+} \p("qρ")$,
$\p("pρ") ≻^k \p("qρ")$).
\begin{proof}
Immediate consequence of \lemma("redcompatall") and the definition of the
relations.
\end{proof}
\end{lem}

=<

=> Classification of processes

We are now going to give the vocabulary that will be used to describe some
specific classes of processes. In particular we need to identify processes
that are to be considered as the evidence of a successful computation, and
those that are to be recognised as the expression of a failure of the
machine (i.e. a crash).
\begin{def}
A process $p ∈ Λ×Π$ is said to be:
\begin{itemize}
\item //final// if $p = \p("v ∗ ε")$ for some value $v ∈ Λ_ι$,
\item //$δ$-like// if $\p("p") = \p("δ(v,w) ∗ π")$ for some values
      $v,w ∈ Λ_ι$ and a stack $π ∈ Π$,
\item //blocked// if there is no $q ∈ Λ×Π$ such that $p ≻ q$,
\item //stuck// if it is not final nor $δ$-like and if $\p("pρ")$ is blocked
      for every substitution $ρ$,
\item //non-terminating// if there is no blocked process $q ∈ Λ×Π$ such that
      $p ≻^{∗} q$.
\end{itemize}
\end{def}
\begin{lem}\label("redstable")
Let $p$ be a process and $ρ$ be a substitution for variables of any kind.
If $p$ is final (resp. stuck, resp. non-terminating, resp. $δ$-like) then
$\p("pρ")$ is also final (resp. stuck, resp. non-terminating, resp.
$δ$-like).
\begin{proof}
Immediate by definition.
\end{proof}
\end{lem}
(* TODO relecture à partir d'ici. *)

\begin{lem}\label("remark")
A stuck state can only be of one of the following forms.
$$
\p("C[v].l ∗ π")
\hspace(2.0)
\p("(λx t).l ∗ π")
\hspace(2.0)
\p("C[v] ∗ w·π")
\hspace(2.0)
\p("{(li = vi) i∈I} ∗ v·π")
$$
$$
\p("[λx t | (Ci[xi] → ti) i∈I] ∗ π")
\hspace(4.0)
\p("[{(li = vi) i∈I} | (Cj[xj] → tj) j∈J] ∗ π")
$$
$$
\p("[D[v] | (Ci[xi] → ti) i∈I] ∗ π") \hspace(2.0) with {D ≠ C_i} for all i∈I
$$
$$
\p("{(li = vi) i∈I}.k ∗ π")      \hspace(2.0) with {k ≠ l_i} for all i∈I
$$
$$
\p("U(λx t) ∗ π")
\hspace(2.0)
\p("U(C[v]) ∗ π")
\hspace(2.0)
\p("U({(li = vi) i∈I≠∅}) ∗ π")
\hspace(2.0)
\p("[x |] ∗ π")
$$
\begin{proof}
  Simple case analysis.
\end{proof}
\end{lem}

\begin{lem}\label("possibilities")
A blocked process $p ∈ Λ×Π$ is either stuck, final, $δ$-like, or of one of
the following forms.
$$
\p("x.l ∗ π")
\hspace(2.0)
\p("x ∗ v·π")
\hspace(2.0)
\p("[x | (Ci[xi] → ti) i∈I≠∅] ∗ π")
$$
$$
\p("a ∗ π")
\hspace(2.0)
\p("U(x) ∗ π")
\hspace(2.0)
\p("v ∗ α")
\hspace(2.0)
\p("v ∗ ε")
$$
\begin{proof}
Straight-forward case analysis using \lemma("remark").
\end{proof}
\end{lem}

=<

=<
