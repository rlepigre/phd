\Include{Macros}
\Caml(
  open ProofTree
  open PMLVerbatim
)

=> Introduction \label("intro")

Program proving is inherently difficult and time consuming. This is probably
the reason why so few programmers care to show the correctness of their
programs formally.
(* *)
The aim of this thesis work is to provide a uniform environment in which
programs can be designed, specified and proved. The idea is to combine a
full-fledged programming language with an enriched type-system allowing
the specification of computational behaviours.
(* *)
Using such a tool, a programmer can adjust the level of guarantees to his
needs, by using more or less fine-grained specifications. The system can thus
be used as ML for type-safe general programming, or as a proof assistant
for proving properties of ML programs.
(* *)
In the system, there is no syntactic distinction between programs and proofs.
Consequently, programming and proving features can be used both in proofs and
in programs. For instance, proofs can be composed as (and with) programs to
form proof tactics. In programs, unreachable branches can be eliminated using
proof mechanisms.
(* *)
The uniformity of the framework implies that programs can be incrementally
refined to obtain more guarantees.

=> ML-style general programming

In this thesis, our first goal is the design of a new type system for a
statically typed functional programming language. We choose to consider a
call-by-value language similar to OCaml or SML, as they have proved to be
higly practical and efficient. In particular, our language provides
polymorphic variants \cite("Garrigue1998") and SML style records, which
are convenient for encoding datatypes. As an example, the type of lists can
be defined and used as follows in our language.
### PML
type rec List(A) = [ Nil | Cons of { hd : A ; tl : List(A) } ]

val rec exists : ∀A (A ⇒ Bool) ⇒ List(A) ⇒ Bool = fun pred l →
  match l with
  | Nil    → Fls
  | Cons c → if pred c.hd then Tru else exists pred c.tl

val rec rev_append : ∀A List(A) ⇒ List(A) ⇒ List(A) = fun la lb →
  match la with
  | Nil    → lb
  | Cons c → rev_concat c.tl (Cons {hd = c.hd ; tl = lb})
###

Like in OCaml or SML, polymorphism is provided to allow more generic
programs. For instance, the functions ##exists## and ##rev_append##
can be applied to lists containing elements of an arbitrary type.
(* *)
In general, ML-like languages only allow a limited form of polymorphism
on let-bindings. In these systems, generalisation can only happen on
expressions of the form ##let x = t in u##. For example, the function
### PML
let silly_ocaml : ('a → 'a) → unit → unit option =
  fun f u → f (Some (f u))
###
is rejected by the OCaml type checker. In our system, polymorphism is not
limited: universal quantification is allowed anywhere in types. As a
consequence, our type system has the full power of Jean-Yves Girard and John
Reynold's System F \mcite(["Girard1972"; "Reynolds1974"]). For example, the
equivalent of
##silly_ocaml##
### PML
val silly : (∀A A → A) → {} → Option({}) =
  fun f u → f (Some (f u))
###
is accepted by our type-checker.

Our language provides a module system encoded using records, and thus
preserving the minimality of our language. The values contained in a module
can be accessed using projection. They can also be made accessible by
//opening// the record, extending the current scope with its fields.
Our system also allows type abstractions encoded using existential types.
For instance, the following type definition corresponds to a module
signature for sets with elements of type ##E##.
### PML
type Set(E) = ∃S { empty : S
                 ; add   : E ⇒ S ⇒ S
                 ; mem   : E ⇒ S ⇒ Bool
                 ; union : S ⇒ S ⇒ S }
###
Using such an encoding for modules, functors correspond to simple functions.
For example, we can implement a functor producing a ##Set## module using
lists.
### PML
type Eq(E) = { equal : E ⇒ E ⇒ Bool }

val makeSet : ∀E Eq(E) ⇒ Set(E) = ∀E fun o →
  { empty : List(E)              = Nil
  ; add   : E ⇒ List(E)         = fun e l → Cons {hd = e ; tl = l}
  ; mem   : E ⇒ List(E) ⇒ Bool = fun e → exists (o.equal e)
  ; union : List(E) ⇒ List(E) ⇒ List(E) = rev_append }
###
A module of type ##Set(E)## can be obtained by providing ##makeSet## with
an equality function on the type ##E##. The functions contained in the
module can then be accessed in the usual way with dot projection. The
abstract type ##S## can be refered to similarly.

The languages of the ML family generally allow operations generating
side-effects like references (i.e. mutable variables). Our system provides
another kind of operations generating side-effects: control operators. As
demonstrated by Timothy G. Griffin \cite("Griffin1990"), control operators
like Lisp's //call/cc// can be used to give a computational interpretation
to classical logic. On the programming side, they can be used to encode an
exception mechanism. For example, the following function can be used to
compute the product of a list of integers rather efficiently.
### PML
val rec product : List(Int) ⇒ Int = fun l → save k →
  match l with
  | Nil    → 1
  | Cons c → if c.hd = 0 then restore k 0
              else mul c.hd (product c.tl)
###
Here, the continuation is saved in a variable ##k## and is restored with
the value ##0## if the absorbing element of multiplication is found in
the list.

=<

=> Proofs of ML programs

The system presented in this thesis is not only a programming language, but
also a proof assistant focusing on program proving. Its proof mechanism
relies on dependent products and equality types $t ≡ u$, where $t$ and $u$
are (possibly untyped) terms of the language itself. Equality types are
interpreted as $\top$ (i.e. truth) if the denoted equivalence holds, and as
$\bot$ (i.e. falsity) otherwise.
(* *)
In our system, a proof is first and foremost a program. For instance, a
pattern-matching corresponds to a case analysis in a proof, and a recursive
call to the use of an induction hypothesis. As a consequence, we may say
that we follow the //program as proof principle//, rather than the usual
//proof as program principle//. In particular, proofs can be composed as
(and with) programs to form proof tactics.

We will now consider several proof examples involving unary natural numbers.
Their type is defined bellow together with the corresponding addition
function.
### PML
type rec Nat = [Zero | Succ of Nat]

val rec add : Nat ⇒ Nat ⇒ Nat = fun n m →
  match n with
  | Zero    → m
  | Succ nn → S (add nn m)
###
As a first example, we are going to show that for every ##n## we have
##add Zero n ≡ n##. To express this property, we quantifiy over program
values to obtain ##∀n (add Zero n ≡ n)##. This statement can then be proved
using the following program.
(*
      ⊢ add Zero x ≡ x
   ---------------------- ✄
    ⊢ ✄ : add Zero x ≡ x       x ∉ FV(·)
   -------------------------------------- ∀i
    ⊢ ✄ : ∀x (add Zero x ≡ x)
*)
### PML
val addZeroN : ∀n (add Zero n ≡ n) = 8<
###
The special term ##8<## (to be pronounced "scissors") can be introduced
whenever the goal is derivable from the context, using equational reasoning.
Our first proof is immediate since we have ##add Zero n ≡ n## by definition
of the ##add## function.

Let us now show that for every ##n## we have ##add n Zero ≡ n##. Although
this property looks similar to the previous one, it is not possible to prove
##∀n (add n Zero ≡ n)## since the equivalence ##add n Zero ≡ n## does not
hold when ##n## is not a unary natural number. Indeed, the computation of
##add n Zero## produces a runtime error in this case.
(* *)
As a consequence, we need to rely on a form of quantification that only
ranges over unary natural numbers. This can be done using the dependent
product type ##(n:Nat) ⇒ (add n Zero ≡ n)##. This property can then be
proved using induction and case analysis.
### PML
let rec addNZero : (n:nat) ⇒ (add n Zero ≡ n) = fun n →
  match n with
  | Zero    → 8<
  | Succ m  → let r = addNZero m in 8<
###
In the ##Succ m## case, the induction hypothesis (i.e. ##add m Zero ≡ m##)
is obtained by a recursive call. It is then used to conclude the proof using
equational reasoning. Note that in our system, programs that are considered
as proofs need to go through a termination checker. Indeed, a looping program
could be used to prove anything otherwise. The proofs ##addZeroN## and
##addNZero## are obviously terminating, and hence valid.

=<

=> On the expressivity of dependent products

Several difficulties arise when combining call-by-value evaluation,
side-effects, dependent products and equality types. Most notably, dependent
products need to be restricted to preserve soundness. Indeed, if ##f## has
type ##(a:A) ⇒ B(a)## and ##t## has type ##A## then we cannot always derive
that ##f t## has type ##B(t)##. As a consequence, we need to restrict the
application of dependent functions so that ##f t## is guaranteed to be of
type ##B(t)##.
(* *)
The simplest possible approach consist in only allowing syntactic values as
argument of dependent functions. This //value restriction// has been
introduced by Andrew Wright \cite("Wright1994") to solve a similar soundness
problem related to polymorphism.

With value restriction, the expressivity of our dependent products
is considerably weakened. In particular, it forbids the application of
##addNZero## to ##add Zero Zero## to obtain a proof of
##add (add Zero Zero) Zero ≡ add Zero Zero##. Indeed, the term
##add Zero Zero## is not a value. As a consequence, value restriction
breaks the modularity of our proof system, as it relies heavily on dependent
products.

Regular programs are also affected by value restriction in a similar way.
For example, it is possible to define a type for vectors (i.e. lists of
fixed length) together with their concatenation function in the following
way.
### PML
val rec len : ∀A List(A) ⇒ Nat = fun l →
  match l with
  | Nil    → Zero
  | Cons c → Succ (len c.tl)

type Vect(A,n) = ∃l (l:List(A) | len l ≡ n)

val rec concat : ∀A (n:Nat) ⇒ (m:Nat) ⇒ Vect(A,n) ⇒ Vect(A,m) ⇒
                      Vect(A,add n m) = fun n m ln lm →
  match n with
  | Zero    → lm
  | Succ nn → (match ln with
               | Nil    → 8<
               | Cons c → let ls = concat nn m c.tl lm in
                            Cons {hd = c.hd; tl = ls})
###
Here, the symbol ##8<## is used to fill a branch of the program that is
not accessible. Indeed, if ##n## is not ##Zero## then the list ##ln##
cannot be equal to ##Nil## by definition of ##Vect(A,n)## (its length
must be equal to ##n##). Let us now suppose that we want to produce,
using ##concat##, a function ##concat3## computing the concatenation of
three vectors. We would expect to be able to define it in the following
way.
### PML
val concat3 : ∀A (n:Nat) ⇒ (m:Nat) ⇒ (k:Nat) ⇒
                   List(n) ⇒ List(m) ⇒ List(k) ⇒
                     List(add (add n m) k) = fun n m k ln lm lk →
  concat (add n m) k (concat n m ln lm) lk
###
However, this definition is not valid with value restriction since
##concat## is applied to the non-value argument ##add n m##. This again
demonstrates that value restruction breaks the modularity of programs
that are typed using dependent products. As a consequence, we need to
relax value restriction so that some well-behaved terms can be used as
arguments for dependent functions.

The equality types provide a solution to our expressivity
problem. The equivalence relation they denote identifies terms (including
values) with the same observable computational behaviour. Hence, equal
terms have the same behaviour on every possible input. Consequently, we
can use a term ##t## as an argument of a dependent function, if an only
if there is a value ##v## such that we can derive ##t ≡ v##. The same idea
can be applied whenever value restriction was previously required, and the
obtained system is conservative over the one with the syntactic
restriction. Indeed, finding a value equivalent to a term that is already
a value can always be done using reflexivity. Although our new idea seems
simple, proving the soundness of the obtained system is surprisingly
subtle \cite("Lepigre2016").

=<

=> Programming with subtyping

Polymorphism and subtyping are essential for programming in a generic way.
They lead to programs that are shorter, easier to understand and hence more
reliable. Although polymorphism is widespread among practical programming
languages, only limited forms of subtyping are used in practice.

(* TODO *)

=<

=> Typing algorithm and bias toward undecidability

... (* TODO *)

=<


=> Main results

The main contribution of this paper is a new approach to value restriction.
The syntactic restriction on terms is replaced by a semantical restriction
expressed in terms of an observational equivalence relation denoted
$({≡})$. Although this approach seems simple, building a model to prove
soundness semantically is surprisingly subtle. Subject reduction is not
required here, as our model construction implies type safety. Furthermore
our type system is consistent as a logic.

In this paper, we restrict ourselves to a second order type system but it
can easily be extended to higher-order. Types are built from two basic sorts
of objects: propositions (the types themselves) and individuals (untyped
terms of the language). Terms appear in a restriction operator
$A \restriction t ≡ u$ and a membership predicate $t ∈ A$. The former is used
to define the equality types (by taking $A = \top$) and the latter is used
to encode dependent product.
$$ Π_{a : A} B := ∀ a (a ∈ A ⇒ B)$$
Overall, the higher-order version of our system is similar to a Curry-style
HOL with ML programs as individuals. It does not allow the definition of a
type which structure depends on a term (e.g. functions with a variable number
of arguments). Our system can thus be placed between HOL (a.k.a. $F_\omega$)
and the pure calculus of constructions (a.k.a. $CoC$) in (a Curry-style and
classical version of) Barendregt's $λ$-cube.

Throughout this paper we build a realizability model à la Krivine
\cite("Krivine2009") based on a call-by-value abstract machine. As a
consequence, formulas are interpreted using three layers (values, stacks
and terms) related via orthogonality. The crucial property for the soundness
of semantical value restriction is that
$$ φ^{\bot\bot} ∩ Λ_v = φ $$
for every set of values $φ$ (closed under $({≡})$). $Λ_v$ denotes the set of
all values and $φ^\bot$ (resp. $φ^{\bot\bot}$) the set of all stacks (resp.
terms) that are compatible with every value in $φ$ (resp. stacks in
$φ^\bot$). To obtain a model satisfying this property, we need to extend our
programming language with a term $δ_{v,w}$ which reduction depends on the
observational equivalence of two values $v$ and $w$.

(*
A model is built using classical
realizability techniques in which the interpretation of a type $A$ is spread
among two sets: a set of values $⟦A⟧$ and a set of terms $⟦A⟧^{\bot\bot}$.
The former contains all values that should have type $A$. For example,
$⟦nat⟧$ should contain the values of the form ##S[S[...Z[]...]]##. The
set $⟦A⟧^{\bot\bot}$ is the completion of $⟦A⟧$ with all the terms behaving
like values of $⟦A⟧$ (in the observational sense).
(* *)
To show that the relaxation of the value restriction is sound, we need the
values of $⟦A⟧^{\bot\bot}$ to also be in $⟦A⟧$. In other words, the
completion operation should not introduce new values. To obtain this
property, we need to extend the language with a new, non-computable
instruction internalizing equivalence. This new instruction is only used to
build the model, and will not be available to the user (nor will it appear
in an implementation).
(* TODO *)
*)

=<

=> Related work

To our knowledge, combining call-by-value evaluation, side-effects and
dependent products has never been achieved before. At least not for a
dependent product fully compatible with effects and call-by-value. For
example, the Aura language \cite("Jia2008") forbids dependency on terms that
are not values in dependent applications. Similarly, the $F^{★}$ language
\cite("Swamy2011") relies on (partial) let-normal forms to enforce values
in argument position. Daniel Licata and Robert Harper have defined a notion
of positively dependent types \cite("Licata2009") which only allow dependency
over strictly positive types.
(* *)
Finally, in language like ATS \cite("Xi2004") and DML \cite("Xi1999")
dependent types are limited to a specific index language.

The system that seems the most similar to ours is NuPrl
\cite("Constable1986"), although it is inconsistent with classical reasoning.
NuPrl accommodates an observational equivalence $({\sim})$ (Howe's squiggle
relation \cite("Howe1989")) similar to our $({≡})$ relation. It is partially
reflected in the syntax of the system. Being based on a Kleene style
realizability model, NuPrl can also be used to reason about untyped terms.

The central part of this paper consists in a classical realizability model
construction in the style of Jean-Louis Krivine \cite("Krivine2009"). We
rely on a call-by-value presentation which yields a model in three layers
(values, terms and stacks). Such a technique has already been used to account
for classical ML-like polymorphism in call-by-value in the work of Guillaume
Munch-Maccagnoni \cite("Munch2009"). It is here extended to include dependent
products. Note that our main theorem seems unrelated to lemma 9 in
Munch-Maccagnoni's work \cite("Munch2009").

The most actively developed proof assistants following the Curry-Howard
correspondence are Coq and Agda \mcite(["CoqTeam2004";"Norell2008"]). The
former is based on Coquand and Huet's calculus of constructions and the
latter on Martin-Löf's dependent type theory \mcite(["Coquand1988";
"Martin-Löf1982"]). These two constructive theories
provide dependent types, which allow the definition of very expressive
specifications. Coq and Agda do not directly give a computational
interpretation to classical logic. Classical reasoning can only be done
through the definition of axioms such as the law of the excluded middle.
Moreover, these two languages are logically consistent, and hence their
type-checkers only allow terminating programs. As termination checking is
a difficult (and undecidable) problem, many terminating programs are
rejected. Although this is not a problem for formalizing mathematics, this
makes programming tedious.

The TRELLYS project \cite("Casinghino2014") aims at providing a language in
which a consistent core can interact with type-safe dependently-typed
programming with general recursion. Although the language defined in
\cite("Casinghino2014") is call-by-value and allows effect, it suffers from
value restriction like Aura \cite("Jia2008"). The value restriction does not
appear explicitly but is encoded into a well-formedness judgement appearing
as the premise of the typing rule for application. Apart from value
restriction, the main difference between the language of the TRELLYS project
and ours resides in the calculus itself. Their calculus is Church-style (or
explicitly typed) while ours is Curry-style (or implicitly typed). In
particular, their terms and types are defined simultaneously, while our type
system is constructed on top of an untyped calculus.

Another similar system can be found in the work of Alexandre Miquel
\cite("Miquel2001"), where propositions can be classical and Curry-style.
However the rest of the language remains Church style and does not embed a
full ML-like language.
(* *)
The PVS system \cite("Owre1996") is similar to ours as it is based on
classical higher-order logic. However this tool does not seem to be a
programming language, but rather a specification language coupled with proof
checking and model checking utilities. It is nonetheless worth mentioning
that the undecidability of PVS's type system is handled by generating proof
obligations. Our system will take a different approach and use a
non-backtracking type-checking and type-inference algorithm.

=<

=> Thesis overview

The type-system of our new language is built incrementally throughout this
thesis. Our starting point is a higher-order language enriched with product
types (corresponding to SML records), sum types (corresponding to
OCaml polymorphic variants) and control operators. This system is
formally constructed in \chapter("hocml"), together with a general
introduction to the concepts and formalisms of type theory and classical
realisability.

The system is then enriched with new types allowing the specification of
program equivalences in \chapter("pml"). In particular, the system is
extended with a dependent product type. However, the expressivity of this
dependent product type is limited due to value restriction. A solution to
this problem is proposed in \chapter("svr"), and value restriction is relaxed.
A realizability model is then constructed to show the soundness of this new
approach. In particular, the property that the biorthogonal completion of
a set of value is closed for values is required.


Every aspect of the system has been implemented in a prototype, which is
distributed with this document.

=<

=<
